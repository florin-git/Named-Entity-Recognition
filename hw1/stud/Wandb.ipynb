{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b79c189e",
   "metadata": {},
   "source": [
    "This notebook collects some trials with Weights and Biases. It is not really cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03998f0f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import random\n",
    "from typing import *\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "SEED = 10\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf2d708",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650264156084,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "6cf2d708",
    "outputId": "644ef401-6efb-43f3-90f4-1d6b2f066c53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "terw36yHE01T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15723,
     "status": "ok",
     "timestamp": 1650264173975,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "terw36yHE01T",
    "outputId": "f3314635-0774-4aa5-a490-be8932be5e1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056b7d8d",
   "metadata": {
    "id": "056b7d8d"
   },
   "source": [
    "# Import from Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46220571",
   "metadata": {
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1650264177987,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "46220571"
   },
   "outputs": [],
   "source": [
    "def read_dataset(data_path: str) -> (List[List[str]], List[List[str]]):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "        Two lists of lists containing sentences and labels respectively.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path: str\n",
    "        Data path of the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    sentences_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    with open(data_path, \"r\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            row = line.strip()\n",
    "            \n",
    "            if row.startswith(\"#\\tid\"): # New sentence\n",
    "                sentence = []\n",
    "                labels = []\n",
    "                \n",
    "            elif row == \"\": # End of the sentence\n",
    "                sentences_list.append(sentence)\n",
    "                labels_list.append(labels)\n",
    "            \n",
    "            else: # Words of a sentence\n",
    "                word, label = row.split('\\t')\n",
    "                \n",
    "                sentence.append(word)\n",
    "                labels.append(label)\n",
    "   \n",
    "    return sentences_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40e261b",
   "metadata": {
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1650264179334,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "e40e261b"
   },
   "outputs": [],
   "source": [
    "# Utility function taken from the 'evaluate.py' script\n",
    "def flat_list(l: List[List[Any]]) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "        A single list containing all elements that\n",
    "        were in the input list.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    l: List[List[Any]]\n",
    "        A list of lists of any type\n",
    "    \"\"\"\n",
    "    return [_e for e in l for _e in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2434bf70",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1650264180454,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "2434bf70"
   },
   "outputs": [],
   "source": [
    "def freq_most_common_tokens(dataset_text: List[List[str]], n: int = 20) -> dict:\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "        The first n common tokens and their frequencies, where the tokens are\n",
    "        retrieved from the list 'dataset_text'.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_text: List[List[str]]\n",
    "        A list of lists of strings. \n",
    "        In this case each nested list is a sentence.\n",
    "    \n",
    "    n: int\n",
    "        Indicates how many tokens to consider.\n",
    "        If it is a negative number, \n",
    "        the function returns the frequencies of all the tokens in the dataset.\n",
    "    \n",
    "    \"\"\"\n",
    "    # The input is flattened\n",
    "    tokens = flat_list(dataset_text)  \n",
    "\n",
    "    # If negative number, return the frequency of all the tokens\n",
    "    if n <= -1:\n",
    "        return dict(Counter(tokens).most_common(len(Counter(tokens))))\n",
    "    else:\n",
    "        return dict(Counter(tokens).most_common(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30104f24",
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1650264186048,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "30104f24"
   },
   "outputs": [],
   "source": [
    "train_pos_dep_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/nlp2022-hw1/data/train_pos_dep.tsv\"\n",
    "valid_pos_dep_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/nlp2022-hw1/data/valid_pos_dep.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e80386b",
   "metadata": {
    "id": "4e80386b"
   },
   "outputs": [],
   "source": [
    "train_pos_dep_path = \"../../data/train_pos_dep.tsv\"\n",
    "valid_pos_dep_path = \"../../data/valid_pos_dep.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a336d627",
   "metadata": {
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1650264189015,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "a336d627"
   },
   "outputs": [],
   "source": [
    "def read_dataset_pos_dep(data_path: str) -> (List[List[str]], List[List[str]], List[List[str]], List[List[str]]):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "        Four lists of lists containing sentences and POS labels,\n",
    "        headwords labels and dependencies labels respectively.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path: str\n",
    "        Data path of the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    sentences_list = []\n",
    "    labels_list = []\n",
    "    heads_list = []\n",
    "    dependencies_list = []\n",
    "    \n",
    "    with open(data_path, \"r\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            row = line.strip()\n",
    "            \n",
    "            if row.startswith(\"#\\tid\"): # New sentence\n",
    "                sentence = []\n",
    "                labels = []\n",
    "                dependencies = []\n",
    "                heads = []\n",
    "                \n",
    "            elif row == \"\": # End of the sentence\n",
    "                sentences_list.append(sentence)\n",
    "                labels_list.append(labels)\n",
    "                heads_list.append(heads)\n",
    "                dependencies_list.append(dependencies)\n",
    "            \n",
    "            else: # Words of a sentence\n",
    "                word, label, head, dep = row.split('\\t')\n",
    "                \n",
    "                sentence.append(word)\n",
    "                labels.append(label)\n",
    "                heads.append(head)\n",
    "                dependencies.append(dep)\n",
    "   \n",
    "    return sentences_list, labels_list, heads_list, dependencies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "342d349f",
   "metadata": {
    "executionInfo": {
     "elapsed": 1777,
     "status": "ok",
     "timestamp": 1650264196154,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "342d349f"
   },
   "outputs": [],
   "source": [
    "_, train_pos, train_heads, train_dep = read_dataset_pos_dep(train_pos_dep_path)\n",
    "_, valid_pos, valid_heads, valid_dep = read_dataset_pos_dep(valid_pos_dep_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "132a69b7",
   "metadata": {
    "id": "132a69b7"
   },
   "outputs": [],
   "source": [
    "train_clean_path = \"../../data/train_clean.tsv\"\n",
    "valid_clean_path = \"../../data/valid_clean.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dHG1ZhDIXd4b",
   "metadata": {
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1650264197839,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "dHG1ZhDIXd4b"
   },
   "outputs": [],
   "source": [
    "train_clean_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/nlp2022-hw1/data/train_clean.tsv\"\n",
    "valid_clean_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/nlp2022-hw1/data/valid_clean.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65304577",
   "metadata": {
    "executionInfo": {
     "elapsed": 922,
     "status": "ok",
     "timestamp": 1650264199849,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "65304577"
   },
   "outputs": [],
   "source": [
    "train_sentences, train_labels = read_dataset(train_clean_path)\n",
    "valid_sentences, valid_labels = read_dataset(valid_clean_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d19e93a1",
   "metadata": {
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1650264202216,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "d19e93a1"
   },
   "outputs": [],
   "source": [
    "pad_token = \"<PAD>\"\n",
    "unk_token = \"<UNK>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa5df520",
   "metadata": {
    "id": "fa5df520"
   },
   "outputs": [],
   "source": [
    "vocab_path = \"../../data/vocab.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f95258ac",
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1650264229219,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "f95258ac"
   },
   "outputs": [],
   "source": [
    "vocab_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/nlp2022-hw1/data/vocab.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7698bb3c",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1650264230514,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "7698bb3c"
   },
   "outputs": [],
   "source": [
    "def read_vocab(path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "        A dictionary that maps tokens to integers.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        Data path of the dictionary.\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    with open(path, 'r', newline=\"\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split('\\t')\n",
    "            vocab[line[0]] = int(line[1])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36588fae",
   "metadata": {
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1650264232347,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "36588fae"
   },
   "outputs": [],
   "source": [
    "vocab = read_vocab(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hKEVFbeZ2s2E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1650264233360,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "hKEVFbeZ2s2E",
    "outputId": "9d4ef23f-80ce-4a0f-a19c-0072dc9f7397"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ba85313",
   "metadata": {
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1650264235338,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "2ba85313"
   },
   "outputs": [],
   "source": [
    "dep_vocab_path = \"../../data/dep_vocab.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "KJTrji0LaffI",
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1650264250602,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "KJTrji0LaffI"
   },
   "outputs": [],
   "source": [
    "dep_vocab_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/nlp2022-hw1/data/dep_vocab.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e481acec",
   "metadata": {
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1650264251918,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "e481acec"
   },
   "outputs": [],
   "source": [
    "dep_vocab = read_vocab(dep_vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df6e18aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1650264252920,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "df6e18aa",
    "outputId": "30e37777-d739-4c34-bc3a-e46c61b6978d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dep_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "214413f9",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1650264255474,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "214413f9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def assign_unique_idx(labels_list: List[List[str]], pad_token: str) -> (dict, dict):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "        Two dictionaries. The first one is a map\n",
    "        from labels to integers; the second one\n",
    "        is the reversed map.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels_list: List[List[str]]\n",
    "        A list of lists of strings. \n",
    "        In this case each nested list is a sentence,\n",
    "        containing labels.\n",
    "        \n",
    "    pad_token: str\n",
    "         String which identifies the padding token.\n",
    "    \"\"\"\n",
    "    labels = freq_most_common_tokens(labels_list, n=-1)\n",
    "    lab2idx = {label: idx+1 for idx, label in enumerate(labels)}\n",
    "    lab2idx[pad_token] = 0 # The padding token is associated to the first position\n",
    "    idx2lab = {idx: label for label, idx in lab2idx.items()} \n",
    "    \n",
    "    return lab2idx, idx2lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3576c55",
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1650264256964,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "c3576c55"
   },
   "outputs": [],
   "source": [
    "lab2idx, idx2lab = assign_unique_idx(train_labels, pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f8bf093",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1650264257988,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "4f8bf093"
   },
   "outputs": [],
   "source": [
    "pos2idx, pos2lab = assign_unique_idx(train_pos, pad_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e9358",
   "metadata": {
    "id": "7a9e9358"
   },
   "source": [
    "# Pretrained Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4gDm3Ll1tFlJ",
   "metadata": {
    "id": "4gDm3Ll1tFlJ"
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f27462",
   "metadata": {
    "id": "63f27462"
   },
   "outputs": [],
   "source": [
    "from gensim.models import *\n",
    "from gensim.models.word2vec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CX8h-yopjSVJ",
   "metadata": {
    "id": "CX8h-yopjSVJ"
   },
   "outputs": [],
   "source": [
    "# ! pip install gensim==4.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1b650",
   "metadata": {
    "id": "b6a1b650"
   },
   "outputs": [],
   "source": [
    "pretrained_vocab_path = \"../../model/vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-wWvenKlGRQA",
   "metadata": {
    "id": "-wWvenKlGRQA"
   },
   "outputs": [],
   "source": [
    "w2v_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/nlp2022-hw1/model/w2v_clean.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AU8pszsVGlZA",
   "metadata": {
    "id": "AU8pszsVGlZA"
   },
   "outputs": [],
   "source": [
    "w2v_path = '../../model/w2v_clean.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c748611",
   "metadata": {
    "id": "4c748611"
   },
   "outputs": [],
   "source": [
    "pretrained_embeddings = torch.load(w2v_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4049d600",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1649311448587,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "4049d600",
    "outputId": "db6b4e35-3e0f-49ac-9d59-65b8cfdc4e19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 300])"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6397e",
   "metadata": {
    "id": "65d6397e"
   },
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45f3f003",
   "metadata": {
    "id": "45f3f003"
   },
   "outputs": [],
   "source": [
    "pretrained_glove_path = \"../../model/pretrained/load_embeddings/pre_glove.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60d0168e",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1650264272959,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "60d0168e"
   },
   "outputs": [],
   "source": [
    "pretrained_glove_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/nlp2022-hw1/model/pretrained/load_embeddings/pre_glove.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c7b4cfb",
   "metadata": {
    "executionInfo": {
     "elapsed": 1504,
     "status": "ok",
     "timestamp": 1650264275643,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "9c7b4cfb"
   },
   "outputs": [],
   "source": [
    "glove_pretrained_embeddings = torch.load(pretrained_glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "000e2333",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1650264276444,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "000e2333",
    "outputId": "e79399f5-1a04-4d32-cd68-0127aa770f32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 100])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_pretrained_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4706e13",
   "metadata": {
    "id": "f4706e13"
   },
   "source": [
    "## Fastext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f8a7da4",
   "metadata": {
    "id": "3f8a7da4"
   },
   "outputs": [],
   "source": [
    "pretrained_fast_path = \"../../model/pretrained/load_embeddings/pre_fast.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ih5htVJFOhWm",
   "metadata": {
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1650264293723,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "ih5htVJFOhWm"
   },
   "outputs": [],
   "source": [
    "pretrained_fast_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/nlp2022-hw1/model/pretrained/load_embeddings/pre_fast.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cabfc47",
   "metadata": {
    "executionInfo": {
     "elapsed": 926,
     "status": "ok",
     "timestamp": 1650264296010,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "1cabfc47"
   },
   "outputs": [],
   "source": [
    "fast_pretrained_embeddings = torch.load(pretrained_fast_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3ec567b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1650264298675,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "a3ec567b",
    "outputId": "7d895a5f-c0d6-4a90-89d3-60f1d20cc4f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 300])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_pretrained_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RJf4B-oNss47",
   "metadata": {
    "id": "RJf4B-oNss47"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cede19b",
   "metadata": {
    "id": "8cede19b"
   },
   "outputs": [],
   "source": [
    "class NER_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences: List[List[str]]\n",
    "        A list of lists of strings where each nested list represents a sentence.\n",
    "        \n",
    "    sentences_labels: List[List[str]]\n",
    "        A list of lists of strings where each nested list represents a sentence,\n",
    "        containing the labels of the tokens.\n",
    "    \"\"\"\n",
    "    def __init__(self, sentences: List[List[str]], sentences_labels: List[List[str]]):\n",
    "\n",
    "        assert len(sentences) == len(sentences_labels), \\\n",
    "                \"Inputs must be of the same length\"\n",
    "        \n",
    "        self.sentences = sentences\n",
    "        self.labels = sentences_labels\n",
    "        \n",
    "        self.sentences_lengths = [len(s) for s in sentences]\n",
    "  \n",
    "        self.Y = self._from_sequence_to_idx(sentences_labels, lab2idx)\n",
    "        self.X = self._from_sequence_to_idx(sentences, vocab, unk_token)\n",
    "     \n",
    "    \n",
    "    def _from_sequence_to_idx(self, sequences_list: List[List[str]],\n",
    "                              vocab: dict, unk_token: str = None) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "            A list of lists of int built by replacing \n",
    "            each token with its corresponding id in the vocabulary.\n",
    "            This is a general function so it works also for labels.\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        sequences_list: List[List[str]]\n",
    "            A list of lists of strings where each nested list represents a sentence.\n",
    "            \n",
    "        vocab: dict\n",
    "            The map that associates to each token an unique number.\n",
    "\n",
    "        unk_token: str\n",
    "            The OOV token.\n",
    "        \"\"\"\n",
    "        \n",
    "        sequences_idx = []\n",
    "        \n",
    "        if unk_token is not None: # For words\n",
    "            for sentence in sequences_list:\n",
    "                sequences_idx.append([vocab.get(token, vocab[unk_token]) for token in sentence])\n",
    "        else: # For labels\n",
    "            for sentence in sequences_list:\n",
    "                sequences_idx.append([vocab.get(token) for token in sentence])\n",
    "        \n",
    "        return sequences_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.Y[idx], self.X[idx], self.sentences_lengths[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d26df73",
   "metadata": {
    "id": "8d26df73"
   },
   "outputs": [],
   "source": [
    "class NER_POS_Dataset(Dataset):\n",
    "    def __init__(self, sentences, sentences_labels, sentences_pos):\n",
    "\n",
    "        assert len(sentences) == len(sentences_labels) == len(sentences_pos), \\\n",
    "                \"Inputs must be of the same length\"\n",
    "        \n",
    "        self.sentences = sentences\n",
    "        self.labels = sentences_labels\n",
    "        self.pos = sentences_pos\n",
    "        \n",
    "        \n",
    "        self.sentences_lengths = [len(s) for s in sentences]\n",
    "#         self.tokens_lengths = [([len(token) for token in sentence]) for sentence in sentences]\n",
    "        \n",
    "        self.Y = self._from_sequence_to_idx(sentences_labels, lab2idx, pad_token)\n",
    "        self.X = self._from_sequence_to_idx(sentences, vocab, pad_token, unk_token)\n",
    "        # POS\n",
    "        self.X_pos = self._from_sequence_to_idx(sentences_pos, pos2idx, pad_token)\n",
    "#         self.X_chars = self._from_tokens_to_char_idx(char_vocab, pad_token, unk_token)\n",
    "        \n",
    "    \n",
    "    def _from_sequence_to_idx(self, sequences_list, vocab, pad_token, unk_token = None):\n",
    "        sequences_idx = []\n",
    "        \n",
    "        if unk_token is not None: # For words\n",
    "            for sentence in sequences_list:\n",
    "                sequences_idx.append([vocab.get(token, vocab[unk_token]) for token in sentence])\n",
    "        else: # For labels\n",
    "            for sentence in sequences_list:\n",
    "                sequences_idx.append([vocab.get(token) for token in sentence])\n",
    "        \n",
    "        return sequences_idx\n",
    "    \n",
    "    def _from_tokens_to_char_idx(self, vocab, pad_token, unk_token):\n",
    "        sequences_idx = []\n",
    "        \n",
    "        for sentence in self.sentences:\n",
    "            sequences_idx.append([[char_vocab.get(c, char_vocab[unk_token]) for c in token] \n",
    "                                     for token in sentence])\n",
    "            \n",
    "        return sequences_idx\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.Y[idx], self.X[idx], self.sentences_lengths[idx], self.X_pos[idx]#, self.X_chars[idx], self.tokens_lengths[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b1f672f",
   "metadata": {
    "id": "5b1f672f"
   },
   "outputs": [],
   "source": [
    "class NER_Dataset(Dataset):\n",
    "    def __init__(self, sentences, sentences_labels):\n",
    "\n",
    "        assert len(sentences) == len(sentences_labels), \\\n",
    "                \"Inputs must be of the same length\"\n",
    "        \n",
    "        self.sentences = sentences\n",
    "        self.labels = sentences_labels\n",
    "        \n",
    "        self.sentences_lengths = [len(s) for s in sentences]\n",
    "#         self.tokens_lengths = [([len(token) for token in sentence]) for sentence in sentences]\n",
    "        \n",
    "        self.Y = self._from_sequence_to_idx(sentences_labels, lab2idx, pad_token)\n",
    "        self.X = self._from_sequence_to_idx(sentences, vocab, pad_token, unk_token)\n",
    "#         self.X_chars = self._from_tokens_to_char_idx(char_vocab, pad_token, unk_token)\n",
    "        \n",
    "    \n",
    "    def _from_sequence_to_idx(self, sequences_list, vocab, pad_token, unk_token = None):\n",
    "        sequences_idx = []\n",
    "        \n",
    "        if unk_token is not None: # For words\n",
    "            for sentence in sequences_list:\n",
    "                sequences_idx.append([vocab.get(token, vocab[unk_token]) for token in sentence])\n",
    "        else: # For labels\n",
    "            for sentence in sequences_list:\n",
    "                sequences_idx.append([vocab.get(token) for token in sentence])\n",
    "        \n",
    "        return sequences_idx\n",
    "    \n",
    "#     def _from_tokens_to_char_idx(self, vocab, pad_token, unk_token):\n",
    "#         sequences_idx = []\n",
    "        \n",
    "#         for sentence in self.sentences:\n",
    "#             sequences_idx.append([[char_vocab.get(c, char_vocab[unk_token]) for c in token] \n",
    "#                                      for token in sentence])\n",
    "            \n",
    "#         return sequences_idx\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.Y[idx], self.X[idx], self.sentences_lengths[idx]#, self.X_chars[idx], self.tokens_lengths[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59924d42",
   "metadata": {
    "id": "59924d42"
   },
   "outputs": [],
   "source": [
    "train_dataset = NER_Dataset(train_sentences, train_labels)\n",
    "valid_dataset = NER_Dataset(valid_sentences, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21f58796",
   "metadata": {
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1650264305898,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "21f58796"
   },
   "outputs": [],
   "source": [
    "def pad_sequence(sequence: List[Any], max_length: int, pad_token: str) -> List[Any]:\n",
    "    padded_sequence = [pad_token] * max_length\n",
    "\n",
    "    for i, token in enumerate(sequence):\n",
    "        padded_sequence[i] = token\n",
    "\n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e73f8ca9",
   "metadata": {
    "id": "e73f8ca9"
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    labels_list = []\n",
    "    features_list = []\n",
    "\n",
    "    labels, features, sentences_lengths = zip(*batch)\n",
    "    \n",
    "    sorted_batch = sorted(zip(labels, features, sentences_lengths), \n",
    "                          key=lambda p: len(p[0]), reverse=True)\n",
    "    labels, features, sentence_lengths = zip(*sorted_batch)\n",
    "    \n",
    "\n",
    "        \n",
    "    max_length_in_batch = np.max(sentence_lengths)\n",
    "    \n",
    "    # Pad sentences and labels to the length of the longest sequence in the batch\n",
    "    for idx, feature in enumerate(features):\n",
    "        features_list.append(pad_sequence(feature, max_length_in_batch, vocab[pad_token]))\n",
    "        labels_list.append(pad_sequence(labels[idx], max_length_in_batch, vocab[pad_token]))\n",
    "      \n",
    "\n",
    "    labels_tensor = torch.LongTensor(labels_list).to(device)\n",
    "    features_tensor = torch.LongTensor(features_list).to(device)\n",
    "\n",
    "    return labels_tensor, features_tensor, sentence_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7-lqFge1XVj_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4201,
     "status": "ok",
     "timestamp": 1650264311980,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "7-lqFge1XVj_",
    "outputId": "bfa3423e-7e19-4e24-8827-0c9507b49374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TorchCRF\n",
      "  Downloading TorchCRF-1.1.0-py3-none-any.whl (5.2 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from TorchCRF) (1.10.0+cu111)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from TorchCRF) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->TorchCRF) (4.1.1)\n",
      "Installing collected packages: TorchCRF\n",
      "Successfully installed TorchCRF-1.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install TorchCRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28727234",
   "metadata": {
    "id": "28727234"
   },
   "outputs": [],
   "source": [
    "from TorchCRF import CRF\n",
    "class NER_Classifier(nn.Module):\n",
    "    def __init__(self, h_params):\n",
    "        super().__init__()\n",
    "\n",
    "        # Fasttext\n",
    "        self.fast_embeddings = self._from_pretrained_embeddings(h_params['fast_embeddings'],\n",
    "                                                               h_params['vocab_size'],\n",
    "                                                               h_params['fast_embed_dim'],\n",
    "                                                               freeze=h_params['freeze_fast'])\n",
    "            \n",
    "            \n",
    "\n",
    "        # Glove\n",
    "        self.glove_embeddings = self._from_pretrained_embeddings(h_params['glove_embeddings'],\n",
    "                                                            h_params['vocab_size'],\n",
    "                                                            h_params['glove_embed_dim'],\n",
    "                                                            freeze=h_params['freeze_glove'], \n",
    "                                                            )\n",
    "        \n",
    "        lstm_input_dim = h_params['fast_embed_dim'] + h_params['glove_embed_dim']\n",
    "        \n",
    "        # Word embeddings\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, \n",
    "                            h_params['lstm_hidden_dim'], \n",
    "                            bidirectional=h_params['bidirectional'],\n",
    "                            num_layers=h_params['num_layers'],\n",
    "                            dropout=h_params['dropout'] if h_params['num_layers'] > 1 else 0,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        \n",
    "        lstm_output_dim = h_params['lstm_hidden_dim'] if h_params['bidirectional'] is False \\\n",
    "                            else h_params['lstm_hidden_dim'] * 2\n",
    "        \n",
    "   \n",
    "        self.dropout = nn.Dropout(h_params['dropout'])  \n",
    "\n",
    "        self.concat = nn.Linear(lstm_output_dim, lstm_output_dim)\n",
    "\n",
    "        self.classifier = nn.Linear(lstm_output_dim, h_params['num_classes'])\n",
    "        \n",
    "        self.relu = nn.LeakyReLU()\n",
    "        \n",
    "        if h_params['use_crf']:\n",
    "            self.crf = CRF(h_params['num_classes'])\n",
    "\n",
    "        self._init_linear_weights()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, x_lengths):\n",
    "        x_fast = self.fast_embeddings(x)\n",
    "        x_glove = self.glove_embeddings(x)\n",
    "        \n",
    "        x = torch.cat((x_fast, x_glove), dim=2)  \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.concat(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        output = self.classifier(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "    def _from_pretrained_embeddings(self, pretrained_embeddings, vocab_size, embed_dim, freeze: bool):\n",
    "        embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        \n",
    "        # Get emebeddings from pretrained ones\n",
    "        embeddings.weight.data.copy_(pretrained_embeddings)\n",
    "        \n",
    "        # Freeze embeddings\n",
    "        embeddings.weight.requires_grad = not freeze \n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    def _init_linear_weights(self):\n",
    "        initrange = 0.5\n",
    "\n",
    "        self.concat.weight.data.uniform_(-initrange, initrange)\n",
    "        self.concat.bias.data.zero_()\n",
    "\n",
    "        self.classifier.weight.data.uniform_(-initrange, initrange)\n",
    "        self.classifier.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97456110",
   "metadata": {
    "id": "97456110"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "T0x3djRLPPGh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9815,
     "status": "ok",
     "timestamp": 1650264321993,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "T0x3djRLPPGh",
    "outputId": "8719b68c-4005-41c4-cb3a-93e08b834c70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 132 kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=56e00243999780315db64c26322ebe01e7487e0768d09192e5fb5d3422d67a40\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "! pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0825c767",
   "metadata": {
    "executionInfo": {
     "elapsed": 1113,
     "status": "ok",
     "timestamp": 1650264323100,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "0825c767"
   },
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "def compute_score(predictions, labels, viterbi_pred = None):\n",
    "    y_true_list = []\n",
    "    y_pred_list = []\n",
    "    \n",
    "    if pad_token != None:\n",
    "        mask = labels != lab2idx[pad_token]\n",
    "        \n",
    "    else:\n",
    "        mask = labels != -1\n",
    "    \n",
    "   \n",
    "    labels = labels[mask].tolist() \n",
    "    y_true = [idx2lab[l] for l in labels]\n",
    "    y_true_list.append(y_true)\n",
    "    \n",
    "    \n",
    "    if viterbi_pred is not None:\n",
    "        y_pred = [idx2lab[l] for l in viterbi_pred]\n",
    "        y_pred_list.append(y_pred)\n",
    "        \n",
    "    else:  \n",
    "        predictions = predictions.argmax(1)\n",
    "        predictions = predictions[mask].tolist()\n",
    "    \n",
    "        y_pred = [idx2lab[l] for l in predictions]\n",
    "        y_pred_list.append(y_pred)\n",
    "\n",
    "    \n",
    "    return f1_score(y_true_list, y_pred_list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "840a27c0",
   "metadata": {
    "id": "840a27c0"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, h_params, optimizer, criterion, grad_clipping):\n",
    "    model.train()    \n",
    "    running_loss = 0.0\n",
    "    f1_score = 0.0\n",
    "    viterbi_pred = None\n",
    "    \n",
    "    for idx, (labels, features, sentences_lengths) in enumerate(dataloader): \n",
    "        # Empty gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        predicted_labels = model(features, sentences_lengths)\n",
    "\n",
    "        \n",
    "        if h_params['use_crf']:\n",
    "            mask = (labels != lab2idx[pad_token])\n",
    "            \n",
    "            log_likelihood = model.crf(predicted_labels, labels, mask=mask)\n",
    "            # Predictions\n",
    "            viterbi_pred = flat_list(model.crf.viterbi_decode(predicted_labels, mask=mask))        \n",
    "                \n",
    "                \n",
    "            # The log likelihood is not normalized \n",
    "            # (It is not divided by the batch size and it is negative)\n",
    "            loss = torch.mean(log_likelihood) * -1\n",
    "\n",
    "            predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "            labels = labels.view(-1)\n",
    "            \n",
    "        else:\n",
    "            predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "            labels = labels.view(-1)\n",
    "            loss = criterion(predicted_labels, labels)\n",
    "            \n",
    "\n",
    "         # Backward  \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Clipping to prevent exploding gradients\n",
    "        if grad_clipping is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clipping)\n",
    "        # Update weights \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "#         f1_score += compute_score(predicted_labels, labels, viterbi_pred)\n",
    "\n",
    "        if idx > 0 and idx % 50 == 0:\n",
    "            metrics = {\"train/batch_loss\": running_loss/idx}\n",
    "            wandb.log(metrics)\n",
    "            \n",
    "    # Loss at the end of the epoch \n",
    "    return running_loss/len(dataloader), f1_score/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1782e42a",
   "metadata": {
    "id": "1782e42a"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, h_params, criterion):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    f1_score = 0.0\n",
    "    viterbi_pred = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (labels, features,sentences_lengths) in enumerate(dataloader):\n",
    "            predicted_labels = model(features, sentences_lengths)\n",
    "            \n",
    "            if h_params['use_crf']:\n",
    "                mask = (labels != lab2idx[pad_token])\n",
    "                log_likelihood = model.crf(predicted_labels, labels, mask=mask) \n",
    "                \n",
    "                viterbi_pred = flat_list(model.crf.viterbi_decode(predicted_labels, mask=mask))        \n",
    "                \n",
    "                \n",
    "                # The log likelihood is not normalized \n",
    "                # (It is not divided by the batch size and it is negative)\n",
    "                loss = torch.mean(log_likelihood) * -1\n",
    "\n",
    "                predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "                labels = labels.view(-1)\n",
    "                \n",
    "\n",
    "            else:\n",
    "                predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "                labels = labels.view(-1)\n",
    "                loss = criterion(predicted_labels, labels)\n",
    "                \n",
    "               \n",
    "            valid_loss += loss.item()\n",
    "            f1_score += compute_score(predicted_labels, labels, viterbi_pred)\n",
    "\n",
    "            if idx > 0 and idx % 10 == 0:\n",
    "                metrics = {\"valid/batch_loss\": valid_loss/idx, \n",
    "                            \"valid/batch_f1\": f1_score/idx}\n",
    "                wandb.log(metrics)\n",
    "            \n",
    "    return valid_loss/len(dataloader), f1_score/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5UN7YnBUiwT8",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1650264323102,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "5UN7YnBUiwT8"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    h_params,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion,\n",
    "    scheduler,\n",
    "    grad_clipping,\n",
    "    epochs: int,\n",
    "    early_stopping: bool = False,\n",
    "    early_stopping_mode: str = 'max',\n",
    "    early_stopping_patience: int = 0,\n",
    "):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    valid_f1_scores = []\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # epoch_time = 0.0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # Train\n",
    "        train_loss, _ = train(model, train_dataloader, h_params,\n",
    "                              optimizer, criterion, grad_clipping)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluate\n",
    "        valid_loss, valid_f1_score = evaluate(model, valid_dataloader,\n",
    "                                             h_params, criterion)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_f1_scores.append(valid_f1_score)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # If the model starts overfitting, then the learning rate is decreased\n",
    "        # if valid_loss is not None and train_loss < valid_loss:\n",
    "        if scheduler is not None:\n",
    "            print(f\"LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        metrics = {\"train/epoch_loss\": train_loss, \n",
    "                    \"valid/epoch_loss\": valid_loss,\n",
    "                    \"valid/f1_score\": valid_f1_score}\n",
    "\n",
    "        wandb.log(metrics)\n",
    "        \n",
    "        print('-' * 100)\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f'| epoch {epoch:3d}/{epochs:d} | time: {epoch_time:5.2f}s | ' \\\n",
    "            f'train_loss: {train_loss:.3f} | valid_loss: {valid_loss:.3f} | valid_f1_score: {valid_f1_score:.3f}')\n",
    "            \n",
    "        print('-' * 100)\n",
    "        \n",
    "        if valid_f1_score < 0.1:\n",
    "            print(\"Too Bad...\")\n",
    "            return\n",
    "        \n",
    "        if early_stopping and len(valid_f1_scores) >= 2:\n",
    "\n",
    "#             stop = early_stopping_mode == 'min' and epoch > 0 and valid_f1_scores[-1] > valid_f1_scores[-2]\n",
    "            stop = early_stopping_mode == 'max' and epoch > 0 and valid_f1_scores[-1] < valid_f1_scores[-2]\n",
    "            if stop:\n",
    "                if patience_counter >= early_stopping_patience:\n",
    "                    print('Early stop.')\n",
    "                    break\n",
    "                else:\n",
    "                    print('-- Patience.\\n')\n",
    "                    patience_counter += 1\n",
    "        \n",
    "        histories = {\n",
    "            \"train_losses\": train_losses,\n",
    "            \"valid_losses\": valid_losses,\n",
    "            \"valid_f1_scores\": valid_f1_scores\n",
    "        }\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9t3QNepnngi8",
   "metadata": {
    "collapsed": true,
    "id": "9t3QNepnngi8"
   },
   "outputs": [],
   "source": [
    "! pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "YyP2oNljndef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 5997,
     "status": "ok",
     "timestamp": 1650264350745,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "YyP2oNljndef",
    "outputId": "ebbc5664-dcf9-4ab2-f3df-dc78d8bd9325"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mflorin-ml\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ScWdkvRJndbo",
   "metadata": {
    "id": "ScWdkvRJndbo"
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }\n",
    "\n",
    "metric = {\n",
    "    'name': 'valid/f1_score',\n",
    "    'goal': 'maximize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    # 'optimizer': {\n",
    "    #     'values': ['sgd'],\n",
    "    #     },\n",
    "    'lstm_hidden_dim': {\n",
    "        'values': [64, 128, 256, 512]\n",
    "        },\n",
    "\n",
    "#     'dropout': {\n",
    "#         'distribution': 'uniform',\n",
    "#         'min': 0.4,\n",
    "#         'max': 0.6,\n",
    "#     },\n",
    "    'dropout': {\n",
    "        \"values\": [.4, .5, .6, .7]\n",
    "    },\n",
    "    \n",
    "    'lr': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.0008,\n",
    "        'max': 0.02,\n",
    "      },\n",
    "    # 'momentum': {\n",
    "    #     'distribution': 'uniform',\n",
    "    #     'min': 0.1,\n",
    "    #     'max': 0.99,\n",
    "    # },\n",
    "    \n",
    "    'grad_clipping': {\n",
    "         # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 1,\n",
    "        'max': 5\n",
    "    },\n",
    "    \n",
    "    \"batch_size\": {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "\n",
    "    \"epochs\": {\n",
    "        'values': [15]\n",
    "    },\n",
    "\n",
    "    # \"freeze_fast\": {\n",
    "    #     \"values\": [True, False]\n",
    "    # },\n",
    "    # \"freeze_glove\": {\n",
    "    #     \"values\": [True, False]\n",
    "    # },\n",
    "    \"freeze_fast\": {\n",
    "        \"values\": [True, False]\n",
    "    },\n",
    "    \"freeze_glove\": {\n",
    "        \"values\": [True, False]\n",
    "    },\n",
    "\n",
    "    \"sceduler_step\": {\n",
    "        'distribution': 'int_uniform',\n",
    "        'min': 5,\n",
    "        'max': 7\n",
    "    },\n",
    "    \"sceduler_gamma\": {\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.1,\n",
    "        'max': 0.6\n",
    "    },\n",
    "    \n",
    "    \"num_layers\": {\n",
    "        \"values\": [2,3]\n",
    "    },    \n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "EWeWpgmbXxZN",
   "metadata": {
    "id": "EWeWpgmbXxZN"
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "\n",
    "metric = {\n",
    "    'name': 'valid/f1_score',\n",
    "    'goal': 'maximize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'lstm_hidden_dim': {\n",
    "        'values': [128, 256, 512]\n",
    "        },\n",
    "\n",
    "    'dropout': {\n",
    "        \"values\": [.4, .5,]\n",
    "    },\n",
    "    \n",
    "    'lr': {\n",
    "        'values': [0.003, 0.004]\n",
    "      },\n",
    "\n",
    "    'grad_clipping': {\n",
    "         \"values\": [0.7, 1, 2, 2.5]\n",
    "    },\n",
    "    \n",
    "    \"batch_size\": {\n",
    "            'values': [64, 128]\n",
    "        },\n",
    "\n",
    "    \"epochs\": {\n",
    "        'values': [12]\n",
    "    },\n",
    "\n",
    "    \"freeze_fast\": {\n",
    "        \"values\": [True]\n",
    "    },\n",
    "    \"freeze_glove\": {\n",
    "        \"values\": [False]\n",
    "    },\n",
    "\n",
    "    \"sceduler_step\": {\n",
    "        \"values\": [4,5,6]\n",
    "    },\n",
    "    \"sceduler_gamma\": {\n",
    "        \"values\": [0.2, 0.3]\n",
    "    },\n",
    "    \n",
    "    \"num_layers\": {\n",
    "        \"values\": [3]\n",
    "    },   \n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "x77LrOVdndaN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1777,
     "status": "ok",
     "timestamp": 1650133053958,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "x77LrOVdndaN",
    "outputId": "ba1f7c88-dc1c-46f9-faf7-66726793f1d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: k1ep9l3e\n",
      "Sweep URL: https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"NLP_HW01_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de7780f7",
   "metadata": {
    "id": "de7780f7"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "def start():\n",
    "\n",
    "    wandb.init(project=\"NLP_HW01_last\")\n",
    "    config = wandb.config\n",
    "\n",
    "    h_params = {\n",
    "        'vocab_size': len(vocab),\n",
    "        'fast_embed_dim': 300,\n",
    "        'freeze_fast': config.freeze_fast,\n",
    "        'glove_embed_dim': 100,\n",
    "        'freeze_glove': config.freeze_glove,\n",
    "        'lstm_hidden_dim': config.lstm_hidden_dim, \n",
    "        'num_classes': len(lab2idx),\n",
    "        'fast_embeddings': fast_pretrained_embeddings,\n",
    "        'glove_embeddings': glove_pretrained_embeddings,\n",
    "        'bidirectional': True,\n",
    "        'num_layers': config.num_layers,\n",
    "        'dropout': config.dropout,\n",
    "        'use_crf': True,  # set to true to test with the Conditional Random Field\n",
    "    }\n",
    "\n",
    "    model = NER_Classifier(h_params).to(device)\n",
    "\n",
    "    # Hyperparameters\n",
    "    epochs = config.epochs # number of epochs\n",
    "    lr = config.lr # learning rate .005\n",
    "    bacth_size = config.batch_size # batch size for training 64\n",
    "    grad_clipping = config.grad_clipping # for clipping gradients         \n",
    "        \n",
    "                                                # ignore the padding class\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=lab2idx[pad_token]).to(device)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.95)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#     scheduler = None\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config['sceduler_step'], gamma=config['sceduler_gamma'])\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[6, 9, 13, 20, 22], gamma=0.1)\n",
    "    # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.002, max_lr=0.01)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=bacth_size, \n",
    "                                collate_fn=collate_batch, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=bacth_size, \n",
    "                                collate_fn=collate_batch, shuffle=False)\n",
    "\n",
    "    histories = train_model(model, train_dataloader, valid_dataloader, h_params, \n",
    "                            optimizer, criterion, scheduler, grad_clipping, epochs,\n",
    "                            early_stopping=True, early_stopping_mode=\"max\", \n",
    "                            early_stopping_patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "Xwfb-ETGndWx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a85176ff3f524c1bb2a3a6bb68160f5e",
      "d3a0a14eb72b4739905a8ebbd4efd1c2",
      "58cfdf686744494a9208d0f49c46179e",
      "8c36f9584e474365ad60aaebb4714339",
      "5d9d2abf40af4f3881fb6f93540cdcd4",
      "3d8d3473a88648f39027681deed3e44e",
      "85c2a66a0c174bc1afb0566d0c5a2839",
      "3476b800a6e2466b9a992546ac59249b",
      "b1fe8ccc787a480294c02630ed544a45",
      "827ba330871b480899f2b9e56d5bed26",
      "2978c09f0df6434e8bfd0b327ed1ad68",
      "2c6c53c5cc974f34b917f04c5854bb09",
      "aaded8f7a5c540ce9a8d5c2bd208870c",
      "3e88a2766f054549b995e42d339bb6ec",
      "d9017b63092e478981e43703016c7732",
      "e89029996ff14433aebc7636e3d50d57",
      "a0a40656168d4aed82b0981be7300590",
      "f8bef87c674345299e0fef8feccc4739",
      "41691a38d63b42f5bbc00c1da9243be1",
      "0712546ebd1e4a22865d943467c61ca2",
      "ae4c077dec1a4df4bd295e0eff3f28d1",
      "2e1a5d81d9534f48b4a2bf4d209aa5b3",
      "e9fb06aa4d5e410a9cec4a592a185a7f",
      "765764bd0c3f43e6b8b7f252740c2a47",
      "476b0d4c1589457c9ee6ec5ee558a359",
      "91a2c027c01348a894e41cd2cd1b160a",
      "2d7e1904f62544f2bd6b049ea4df6898",
      "bfae5df962da49888da011f94d0b48ac",
      "06de670d653c4271abddba393d1e3a26",
      "905fc698eb874106ae2d21f594c22157",
      "dfa78dbf050b4edb8da3844808d2f11f",
      "eee0071b7d10470c98d94f1244e8d4d3",
      "efd356d12409446f8c63bc34bb66d19f",
      "c62144738d5f418f9e428d1b5c662775",
      "14911de88f8e49b7907f13409fc427d5",
      "fde3655a2076428186cef6603d45ce66",
      "9e2b12fa35bf4486980540768670d8a5",
      "25a051869db74c3eaf7751dbd3e6a4b7",
      "9d3bd75b7c0f4db385e631b2b808679d",
      "e8dbb309fb1746beab9a8fd003fed624",
      "1c51867d12494c07a5e3b0ea98cab176",
      "892ae65ecf4940ac881daf2910cbb6b7",
      "0d3b7bc31de14c2f941c0311f6c1b57f",
      "839c58584d874b7fa20f2d1de206c931",
      "c1afc5b7695245738aaf09187fdde5ab",
      "1490b01999a1429eb118d4a4379524b1",
      "1b588a4698f646c0a844c3250cd46a20",
      "0e81969779634e53bf837046e85c1e2b",
      "3bf90e06e0984e7b9b785af1717e90ad",
      "909e333c1e4c458ab05f044e76c479b8",
      "5f360bcd113e4c4aaefbf7ebfe501938",
      "ec61ade6d59346f0842c1fa3f055dbcd",
      "a7deb98f417b49cb9f9bb3e090c25d2b",
      "b8f9255a9a2a4c498b2d59dc0725fed4",
      "09e323dafcbb453995937940ccfc682c",
      "47d3f588d0d44eb8b537e471857be23f",
      "30e9f82c423049ffbb4b4b84c73248d4",
      "77773eb6e53e45ee993bc9ab3b84b478",
      "99d795c55d3b4b0d9e89ef9bc4a9723e",
      "00fe27225b0a449aae027737945df70d",
      "56109661560c488ea58ee9ad5d5c4684",
      "75500b44ec5f46b787b278981b91eadc",
      "d1ebdcf4285642c392a0fad22659ada7",
      "5fb8b642acf14f0b971816c07dbb121f",
      "ce6332a62a7946728f876cdebb64f68f",
      "207f8a637d5943ffafb7e900a3041cde",
      "a8382fa2e9d245a18111612c0ded8c50",
      "e85a62e2f8a847ae982f43321ad90f13",
      "6fd5b2be54654b2ba644d0049f5f93b5",
      "ed4c46828a9c4aeebe60991aa0b8adc3",
      "cfc354da138b47c1b3b07b885b115534",
      "01e23759828c4e2bbed10ab5561f06b7",
      "9305ee92e3ea4bb9b2db61300189fe66",
      "54bbc180718643859d30d49b38f36f26",
      "09d32109df444907a30761ee05ebdbd5",
      "214b8b5f1aeb43fd8983757ee13f1c91",
      "8db0a4f9faf44b47a44aac218958faad",
      "b65db98563784625a0f61372b3568b1f",
      "59dd067dc77b4febbf3a93f250003c4c",
      "13bee564ce304190801bea63aeed3ef3",
      ""
     ]
    },
    "executionInfo": {
     "elapsed": 2786553,
     "status": "ok",
     "timestamp": 1650135846002,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "Xwfb-ETGndWx",
    "outputId": "c6c3146c-faae-4976-c741-c5896000b49b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tali5fso with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_174653-tali5fso</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/tali5fso\" target=\"_blank\">pleasant-sweep-2</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 26.97s | train_loss: 6.579 | valid_loss: 4.032 | valid_f1_score: 0.543\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 28.46s | train_loss: 3.262 | valid_loss: 2.873 | valid_f1_score: 0.623\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 28.29s | train_loss: 2.265 | valid_loss: 2.613 | valid_f1_score: 0.674\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 28.20s | train_loss: 1.779 | valid_loss: 2.433 | valid_f1_score: 0.687\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 28.17s | train_loss: 1.432 | valid_loss: 2.199 | valid_f1_score: 0.681\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 28.69s | train_loss: 1.049 | valid_loss: 2.234 | valid_f1_score: 0.704\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 28.31s | train_loss: 0.913 | valid_loss: 2.273 | valid_f1_score: 0.702\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 28.14s | train_loss: 0.863 | valid_loss: 2.254 | valid_f1_score: 0.710\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 28.48s | train_loss: 0.805 | valid_loss: 2.304 | valid_f1_score: 0.710\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▆▅▅▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▂▂▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▄▇▇▇████</td></tr><tr><td>valid/batch_loss</td><td>█▄▃▂▁▁▁▁▁</td></tr><tr><td>valid/epoch_loss</td><td>█▄▃▂▁▁▁▁▁</td></tr><tr><td>valid/f1_score</td><td>▁▄▆▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.81441</td></tr><tr><td>train/epoch_loss</td><td>0.8054</td></tr><tr><td>valid/batch_f1</td><td>0.78479</td></tr><tr><td>valid/batch_loss</td><td>2.50398</td></tr><tr><td>valid/epoch_loss</td><td>2.30437</td></tr><tr><td>valid/f1_score</td><td>0.70963</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pleasant-sweep-2</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/tali5fso\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/tali5fso</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_174653-tali5fso\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ty5jwkj6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_175129-ty5jwkj6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/ty5jwkj6\" target=\"_blank\">true-sweep-3</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 27.81s | train_loss: 6.575 | valid_loss: 4.129 | valid_f1_score: 0.544\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 28.43s | train_loss: 3.209 | valid_loss: 2.975 | valid_f1_score: 0.615\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 28.29s | train_loss: 2.240 | valid_loss: 2.470 | valid_f1_score: 0.652\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 28.92s | train_loss: 1.732 | valid_loss: 2.280 | valid_f1_score: 0.680\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 28.55s | train_loss: 1.418 | valid_loss: 2.220 | valid_f1_score: 0.686\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 28.43s | train_loss: 1.210 | valid_loss: 2.265 | valid_f1_score: 0.685\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 28.36s | train_loss: 0.885 | valid_loss: 2.193 | valid_f1_score: 0.699\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 28.20s | train_loss: 0.776 | valid_loss: 2.281 | valid_f1_score: 0.708\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 28.55s | train_loss: 0.739 | valid_loss: 2.240 | valid_f1_score: 0.700\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/12 | time: 28.63s | train_loss: 0.673 | valid_loss: 2.360 | valid_f1_score: 0.717\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  11/12 | time: 28.14s | train_loss: 0.653 | valid_loss: 2.334 | valid_f1_score: 0.707\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▆▆▅▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▄▅▇▇▇▇█▇█▇</td></tr><tr><td>valid/batch_loss</td><td>█▄▂▁▁▁▁▁▁▂▂</td></tr><tr><td>valid/epoch_loss</td><td>█▄▂▁▁▁▁▁▁▂▂</td></tr><tr><td>valid/f1_score</td><td>▁▄▅▆▇▇▇█▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.64932</td></tr><tr><td>train/epoch_loss</td><td>0.65253</td></tr><tr><td>valid/batch_f1</td><td>0.78439</td></tr><tr><td>valid/batch_loss</td><td>2.55786</td></tr><tr><td>valid/epoch_loss</td><td>2.33372</td></tr><tr><td>valid/f1_score</td><td>0.70693</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-sweep-3</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/ty5jwkj6\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/ty5jwkj6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_175129-ty5jwkj6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q0m8kkqd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_175656-q0m8kkqd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/q0m8kkqd\" target=\"_blank\">vital-sweep-4</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 30.68s | train_loss: 6.477 | valid_loss: 4.095 | valid_f1_score: 0.533\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 31.82s | train_loss: 3.205 | valid_loss: 2.822 | valid_f1_score: 0.626\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 31.96s | train_loss: 2.242 | valid_loss: 2.482 | valid_f1_score: 0.648\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 31.56s | train_loss: 1.741 | valid_loss: 2.296 | valid_f1_score: 0.685\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 31.47s | train_loss: 1.266 | valid_loss: 2.143 | valid_f1_score: 0.694\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 31.65s | train_loss: 1.113 | valid_loss: 2.194 | valid_f1_score: 0.704\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 31.48s | train_loss: 1.003 | valid_loss: 2.162 | valid_f1_score: 0.707\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 31.54s | train_loss: 0.915 | valid_loss: 2.246 | valid_f1_score: 0.705\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000270\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 31.71s | train_loss: 0.805 | valid_loss: 2.254 | valid_f1_score: 0.708\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000270\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/12 | time: 31.20s | train_loss: 0.766 | valid_loss: 2.268 | valid_f1_score: 0.707\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000270\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  11/12 | time: 31.47s | train_loss: 0.738 | valid_loss: 2.299 | valid_f1_score: 0.708\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000270\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  12/12 | time: 31.59s | train_loss: 0.718 | valid_loss: 2.333 | valid_f1_score: 0.708\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▆▅▅▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▅▆▇████████</td></tr><tr><td>valid/batch_loss</td><td>█▃▂▁▁▁▁▁▁▁▂▂</td></tr><tr><td>valid/epoch_loss</td><td>█▃▂▂▁▁▁▁▁▁▂▂</td></tr><tr><td>valid/f1_score</td><td>▁▅▆▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.71926</td></tr><tr><td>train/epoch_loss</td><td>0.71846</td></tr><tr><td>valid/batch_f1</td><td>0.77994</td></tr><tr><td>valid/batch_loss</td><td>2.56982</td></tr><tr><td>valid/epoch_loss</td><td>2.33266</td></tr><tr><td>valid/f1_score</td><td>0.7077</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vital-sweep-4</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/q0m8kkqd\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/q0m8kkqd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_175656-q0m8kkqd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s5xajp0t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_180334-s5xajp0t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/s5xajp0t\" target=\"_blank\">ruby-sweep-5</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 27.14s | train_loss: 6.622 | valid_loss: 3.962 | valid_f1_score: 0.527\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 28.90s | train_loss: 3.226 | valid_loss: 2.830 | valid_f1_score: 0.613\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 28.80s | train_loss: 2.267 | valid_loss: 2.544 | valid_f1_score: 0.654\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 28.54s | train_loss: 1.756 | valid_loss: 2.320 | valid_f1_score: 0.694\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 28.51s | train_loss: 1.426 | valid_loss: 2.259 | valid_f1_score: 0.678\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 28.35s | train_loss: 1.044 | valid_loss: 2.207 | valid_f1_score: 0.708\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 28.68s | train_loss: 0.919 | valid_loss: 2.205 | valid_f1_score: 0.709\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 31.34s | train_loss: 0.839 | valid_loss: 2.279 | valid_f1_score: 0.705\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 32.19s | train_loss: 0.774 | valid_loss: 2.349 | valid_f1_score: 0.708\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/12 | time: 29.54s | train_loss: 0.723 | valid_loss: 2.339 | valid_f1_score: 0.711\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000270\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  11/12 | time: 28.28s | train_loss: 0.627 | valid_loss: 2.397 | valid_f1_score: 0.716\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000270\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  12/12 | time: 28.23s | train_loss: 0.608 | valid_loss: 2.463 | valid_f1_score: 0.710\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▆▆▅▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▄▆▇▆██▇████</td></tr><tr><td>valid/batch_loss</td><td>█▃▂▁▁▁▁▁▂▂▂▂</td></tr><tr><td>valid/epoch_loss</td><td>█▃▂▁▁▁▁▁▂▂▂▂</td></tr><tr><td>valid/f1_score</td><td>▁▄▆▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.60975</td></tr><tr><td>train/epoch_loss</td><td>0.60787</td></tr><tr><td>valid/batch_f1</td><td>0.78862</td></tr><tr><td>valid/batch_loss</td><td>2.69122</td></tr><tr><td>valid/epoch_loss</td><td>2.4627</td></tr><tr><td>valid/f1_score</td><td>0.71025</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ruby-sweep-5</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/s5xajp0t\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/s5xajp0t</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_180334-s5xajp0t\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qgsqxcks with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_180954-qgsqxcks</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/qgsqxcks\" target=\"_blank\">rose-sweep-6</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 27.07s | train_loss: 6.678 | valid_loss: 4.118 | valid_f1_score: 0.516\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 28.38s | train_loss: 3.215 | valid_loss: 2.837 | valid_f1_score: 0.623\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 28.96s | train_loss: 2.286 | valid_loss: 2.577 | valid_f1_score: 0.642\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 29.35s | train_loss: 1.772 | valid_loss: 2.351 | valid_f1_score: 0.683\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 28.60s | train_loss: 1.431 | valid_loss: 2.230 | valid_f1_score: 0.694\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 30.91s | train_loss: 1.201 | valid_loss: 2.344 | valid_f1_score: 0.695\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 30.59s | train_loss: 0.883 | valid_loss: 2.345 | valid_f1_score: 0.702\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 31.33s | train_loss: 0.775 | valid_loss: 2.392 | valid_f1_score: 0.704\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 30.83s | train_loss: 0.716 | valid_loss: 2.372 | valid_f1_score: 0.710\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/12 | time: 30.97s | train_loss: 0.664 | valid_loss: 2.533 | valid_f1_score: 0.713\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  11/12 | time: 32.11s | train_loss: 0.608 | valid_loss: 2.529 | valid_f1_score: 0.706\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  12/12 | time: 31.04s | train_loss: 0.582 | valid_loss: 2.574 | valid_f1_score: 0.714\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▆▆▅▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▅▅▇▇▇██████</td></tr><tr><td>valid/batch_loss</td><td>█▃▂▁▁▁▁▂▂▂▂▂</td></tr><tr><td>valid/epoch_loss</td><td>█▃▂▁▁▁▁▂▂▂▂▂</td></tr><tr><td>valid/f1_score</td><td>▁▅▅▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.5866</td></tr><tr><td>train/epoch_loss</td><td>0.58236</td></tr><tr><td>valid/batch_f1</td><td>0.79097</td></tr><tr><td>valid/batch_loss</td><td>2.81084</td></tr><tr><td>valid/epoch_loss</td><td>2.5736</td></tr><tr><td>valid/f1_score</td><td>0.71359</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rose-sweep-6</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/qgsqxcks\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/qgsqxcks</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_180954-qgsqxcks\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l8j5frmu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_181609-l8j5frmu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/l8j5frmu\" target=\"_blank\">rose-sweep-7</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 33.82s | train_loss: 7.095 | valid_loss: 3.902 | valid_f1_score: 0.543\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 33.40s | train_loss: 3.127 | valid_loss: 2.941 | valid_f1_score: 0.612\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 31.30s | train_loss: 2.132 | valid_loss: 2.472 | valid_f1_score: 0.668\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 31.02s | train_loss: 1.621 | valid_loss: 2.214 | valid_f1_score: 0.687\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 30.84s | train_loss: 1.078 | valid_loss: 2.200 | valid_f1_score: 0.702\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 30.98s | train_loss: 0.926 | valid_loss: 2.188 | valid_f1_score: 0.714\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 31.10s | train_loss: 0.821 | valid_loss: 2.222 | valid_f1_score: 0.714\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 30.91s | train_loss: 0.766 | valid_loss: 2.262 | valid_f1_score: 0.709\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000120\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 31.16s | train_loss: 0.664 | valid_loss: 2.314 | valid_f1_score: 0.719\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000120\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/12 | time: 31.90s | train_loss: 0.624 | valid_loss: 2.373 | valid_f1_score: 0.716\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000120\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  11/12 | time: 33.76s | train_loss: 0.607 | valid_loss: 2.417 | valid_f1_score: 0.716\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▆▅▅▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▂▂▁▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▄▆▇▇██████</td></tr><tr><td>valid/batch_loss</td><td>█▄▂▁▁▁▁▁▁▂▂</td></tr><tr><td>valid/epoch_loss</td><td>█▄▂▁▁▁▁▁▂▂▂</td></tr><tr><td>valid/f1_score</td><td>▁▄▆▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.61036</td></tr><tr><td>train/epoch_loss</td><td>0.60651</td></tr><tr><td>valid/batch_f1</td><td>0.78866</td></tr><tr><td>valid/batch_loss</td><td>2.6266</td></tr><tr><td>valid/epoch_loss</td><td>2.417</td></tr><tr><td>valid/f1_score</td><td>0.7159</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rose-sweep-7</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/l8j5frmu\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/l8j5frmu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_181609-l8j5frmu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q5v315lv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_182355-q5v315lv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/q5v315lv\" target=\"_blank\">icy-sweep-8</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 27.73s | train_loss: 7.261 | valid_loss: 3.684 | valid_f1_score: 0.558\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 29.44s | train_loss: 3.062 | valid_loss: 2.741 | valid_f1_score: 0.636\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 29.32s | train_loss: 2.129 | valid_loss: 2.294 | valid_f1_score: 0.671\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 29.43s | train_loss: 1.604 | valid_loss: 2.323 | valid_f1_score: 0.682\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 29.47s | train_loss: 1.305 | valid_loss: 2.153 | valid_f1_score: 0.700\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 29.29s | train_loss: 0.877 | valid_loss: 2.147 | valid_f1_score: 0.726\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 29.34s | train_loss: 0.750 | valid_loss: 2.222 | valid_f1_score: 0.729\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 29.52s | train_loss: 0.676 | valid_loss: 2.233 | valid_f1_score: 0.720\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 31.61s | train_loss: 0.621 | valid_loss: 2.293 | valid_f1_score: 0.726\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/12 | time: 32.43s | train_loss: 0.550 | valid_loss: 2.407 | valid_f1_score: 0.729\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000120\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  11/12 | time: 32.24s | train_loss: 0.488 | valid_loss: 2.420 | valid_f1_score: 0.729\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000120\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  12/12 | time: 31.98s | train_loss: 0.470 | valid_loss: 2.440 | valid_f1_score: 0.728\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▆▅▅▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▄▆▆▇███████</td></tr><tr><td>valid/batch_loss</td><td>█▄▂▂▁▁▁▁▂▂▂▂</td></tr><tr><td>valid/epoch_loss</td><td>█▄▂▂▁▁▁▁▂▂▂▂</td></tr><tr><td>valid/f1_score</td><td>▁▄▆▆▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.47182</td></tr><tr><td>train/epoch_loss</td><td>0.47019</td></tr><tr><td>valid/batch_f1</td><td>0.80422</td></tr><tr><td>valid/batch_loss</td><td>2.66585</td></tr><tr><td>valid/epoch_loss</td><td>2.44002</td></tr><tr><td>valid/f1_score</td><td>0.7285</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">icy-sweep-8</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/q5v315lv\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/q5v315lv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_182355-q5v315lv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: shwuocf1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_183016-shwuocf1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/shwuocf1\" target=\"_blank\">hopeful-sweep-9</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 32.56s | train_loss: 7.024 | valid_loss: 3.964 | valid_f1_score: 0.540\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 32.24s | train_loss: 3.096 | valid_loss: 2.731 | valid_f1_score: 0.613\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 32.23s | train_loss: 2.131 | valid_loss: 2.375 | valid_f1_score: 0.654\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 31.79s | train_loss: 1.619 | valid_loss: 2.353 | valid_f1_score: 0.681\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 31.88s | train_loss: 1.305 | valid_loss: 2.316 | valid_f1_score: 0.686\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 32.18s | train_loss: 1.079 | valid_loss: 2.308 | valid_f1_score: 0.701\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 32.08s | train_loss: 0.739 | valid_loss: 2.330 | valid_f1_score: 0.714\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 31.89s | train_loss: 0.629 | valid_loss: 2.417 | valid_f1_score: 0.715\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 31.92s | train_loss: 0.558 | valid_loss: 2.457 | valid_f1_score: 0.716\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/12 | time: 31.31s | train_loss: 0.507 | valid_loss: 2.565 | valid_f1_score: 0.722\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  11/12 | time: 29.83s | train_loss: 0.471 | valid_loss: 2.640 | valid_f1_score: 0.716\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  12/12 | time: 31.73s | train_loss: 0.433 | valid_loss: 2.609 | valid_f1_score: 0.722\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▆▅▅▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▄▅▆▆▇██████</td></tr><tr><td>valid/batch_loss</td><td>█▃▁▁▁▁▁▁▂▂▂▂</td></tr><tr><td>valid/epoch_loss</td><td>█▃▁▁▁▁▁▁▂▂▂▂</td></tr><tr><td>valid/f1_score</td><td>▁▄▅▆▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.42927</td></tr><tr><td>train/epoch_loss</td><td>0.43321</td></tr><tr><td>valid/batch_f1</td><td>0.80378</td></tr><tr><td>valid/batch_loss</td><td>2.84156</td></tr><tr><td>valid/epoch_loss</td><td>2.60851</td></tr><tr><td>valid/f1_score</td><td>0.72233</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hopeful-sweep-9</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/shwuocf1\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/shwuocf1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_183016-shwuocf1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jd9vykc9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_183654-jd9vykc9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/jd9vykc9\" target=\"_blank\">royal-sweep-10</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 38.30s | train_loss: 6.921 | valid_loss: 4.014 | valid_f1_score: 0.501\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 42.77s | train_loss: 3.108 | valid_loss: 2.830 | valid_f1_score: 0.641\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 33.49s | train_loss: 2.107 | valid_loss: 2.524 | valid_f1_score: 0.655\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 32.60s | train_loss: 1.585 | valid_loss: 2.216 | valid_f1_score: 0.684\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 32.96s | train_loss: 1.097 | valid_loss: 2.215 | valid_f1_score: 0.714\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 33.23s | train_loss: 0.931 | valid_loss: 2.164 | valid_f1_score: 0.707\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 33.84s | train_loss: 0.821 | valid_loss: 2.300 | valid_f1_score: 0.708\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 33.20s | train_loss: 0.740 | valid_loss: 2.334 | valid_f1_score: 0.712\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000270\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 33.25s | train_loss: 0.613 | valid_loss: 2.384 | valid_f1_score: 0.717\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000270\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/12 | time: 34.50s | train_loss: 0.561 | valid_loss: 2.491 | valid_f1_score: 0.710\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000270\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  11/12 | time: 33.02s | train_loss: 0.536 | valid_loss: 2.502 | valid_f1_score: 0.718\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000270\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  12/12 | time: 33.40s | train_loss: 0.508 | valid_loss: 2.525 | valid_f1_score: 0.706\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▆▅▅▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▅▆▇████████</td></tr><tr><td>valid/batch_loss</td><td>█▃▂▁▁▁▂▂▂▂▂▂</td></tr><tr><td>valid/epoch_loss</td><td>█▄▂▁▁▁▂▂▂▂▂▂</td></tr><tr><td>valid/f1_score</td><td>▁▆▆▇████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.51111</td></tr><tr><td>train/epoch_loss</td><td>0.50751</td></tr><tr><td>valid/batch_f1</td><td>0.78181</td></tr><tr><td>valid/batch_loss</td><td>2.76737</td></tr><tr><td>valid/epoch_loss</td><td>2.5251</td></tr><tr><td>valid/f1_score</td><td>0.7062</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">royal-sweep-10</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/jd9vykc9\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/jd9vykc9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_183654-jd9vykc9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oyn0bqae with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_184405-oyn0bqae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/oyn0bqae\" target=\"_blank\">rosy-sweep-11</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 32.84s | train_loss: 6.810 | valid_loss: 4.107 | valid_f1_score: 0.555\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 32.51s | train_loss: 3.080 | valid_loss: 2.748 | valid_f1_score: 0.652\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 32.92s | train_loss: 2.127 | valid_loss: 2.384 | valid_f1_score: 0.654\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 31.70s | train_loss: 1.620 | valid_loss: 2.235 | valid_f1_score: 0.699\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 31.89s | train_loss: 1.298 | valid_loss: 2.153 | valid_f1_score: 0.698\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 32.54s | train_loss: 0.885 | valid_loss: 2.226 | valid_f1_score: 0.721\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 31.47s | train_loss: 0.759 | valid_loss: 2.320 | valid_f1_score: 0.721\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 31.46s | train_loss: 0.642 | valid_loss: 2.392 | valid_f1_score: 0.719\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 31.30s | train_loss: 0.604 | valid_loss: 2.354 | valid_f1_score: 0.722\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/12 | time: 31.25s | train_loss: 0.542 | valid_loss: 2.399 | valid_f1_score: 0.722\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▆▅▅▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▂▂▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▅▅▇▇█████</td></tr><tr><td>valid/batch_loss</td><td>█▃▂▁▁▁▂▂▂▂</td></tr><tr><td>valid/epoch_loss</td><td>█▃▂▁▁▁▂▂▂▂</td></tr><tr><td>valid/f1_score</td><td>▁▅▅▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.53757</td></tr><tr><td>train/epoch_loss</td><td>0.54249</td></tr><tr><td>valid/batch_f1</td><td>0.79874</td></tr><tr><td>valid/batch_loss</td><td>2.62397</td></tr><tr><td>valid/epoch_loss</td><td>2.39894</td></tr><tr><td>valid/f1_score</td><td>0.72204</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rosy-sweep-11</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/oyn0bqae\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/oyn0bqae</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_184405-oyn0bqae\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: at1eo3nn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_184942-at1eo3nn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/at1eo3nn\" target=\"_blank\">cosmic-sweep-12</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 32.42s | train_loss: 6.702 | valid_loss: 4.250 | valid_f1_score: 0.505\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 31.93s | train_loss: 3.110 | valid_loss: 2.803 | valid_f1_score: 0.636\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 31.14s | train_loss: 2.136 | valid_loss: 2.377 | valid_f1_score: 0.681\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 31.11s | train_loss: 1.612 | valid_loss: 2.288 | valid_f1_score: 0.683\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 31.15s | train_loss: 1.312 | valid_loss: 2.362 | valid_f1_score: 0.683\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 31.05s | train_loss: 1.080 | valid_loss: 2.266 | valid_f1_score: 0.713\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 32.85s | train_loss: 0.740 | valid_loss: 2.292 | valid_f1_score: 0.725\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 32.13s | train_loss: 0.617 | valid_loss: 2.397 | valid_f1_score: 0.721\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 33.56s | train_loss: 0.551 | valid_loss: 2.464 | valid_f1_score: 0.714\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/12 | time: 33.46s | train_loss: 0.476 | valid_loss: 2.573 | valid_f1_score: 0.726\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  11/12 | time: 32.06s | train_loss: 0.451 | valid_loss: 2.585 | valid_f1_score: 0.718\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▆▅▅▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▂▂▂▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▅▇▇▇██████</td></tr><tr><td>valid/batch_loss</td><td>█▃▁▁▁▁▁▂▂▂▂</td></tr><tr><td>valid/epoch_loss</td><td>█▃▁▁▁▁▁▁▂▂▂</td></tr><tr><td>valid/f1_score</td><td>▁▅▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.44678</td></tr><tr><td>train/epoch_loss</td><td>0.45074</td></tr><tr><td>valid/batch_f1</td><td>0.7963</td></tr><tr><td>valid/batch_loss</td><td>2.83575</td></tr><tr><td>valid/epoch_loss</td><td>2.58505</td></tr><tr><td>valid/f1_score</td><td>0.71758</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cosmic-sweep-12</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/at1eo3nn\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/at1eo3nn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_184942-at1eo3nn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5h9y1403 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_185554-5h9y1403</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/5h9y1403\" target=\"_blank\">vague-sweep-13</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 43.28s | train_loss: 13.574 | valid_loss: 3.938 | valid_f1_score: 0.513\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 43.40s | train_loss: 3.066 | valid_loss: 2.952 | valid_f1_score: 0.629\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 44.81s | train_loss: 2.077 | valid_loss: 2.434 | valid_f1_score: 0.690\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 45.90s | train_loss: 1.568 | valid_loss: 2.217 | valid_f1_score: 0.688\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 44.68s | train_loss: 0.992 | valid_loss: 2.157 | valid_f1_score: 0.719\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 45.03s | train_loss: 0.822 | valid_loss: 2.236 | valid_f1_score: 0.716\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 45.82s | train_loss: 0.703 | valid_loss: 2.274 | valid_f1_score: 0.724\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 45.64s | train_loss: 0.633 | valid_loss: 2.320 | valid_f1_score: 0.721\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▂▂▂▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▅▇▇████</td></tr><tr><td>valid/batch_loss</td><td>█▄▂▁▁▁▁▂</td></tr><tr><td>valid/epoch_loss</td><td>█▄▂▁▁▁▁▂</td></tr><tr><td>valid/f1_score</td><td>▁▅▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.6282</td></tr><tr><td>train/epoch_loss</td><td>0.6334</td></tr><tr><td>valid/batch_f1</td><td>0.79486</td></tr><tr><td>valid/batch_loss</td><td>2.54668</td></tr><tr><td>valid/epoch_loss</td><td>2.32027</td></tr><tr><td>valid/f1_score</td><td>0.72105</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vague-sweep-13</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/5h9y1403\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/5h9y1403</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_185554-5h9y1403\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ro79lgid with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_190210-ro79lgid</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/ro79lgid\" target=\"_blank\">happy-sweep-14</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 45.29s | train_loss: 12.166 | valid_loss: 3.960 | valid_f1_score: 0.564\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 44.65s | train_loss: 3.131 | valid_loss: 2.714 | valid_f1_score: 0.625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 44.96s | train_loss: 2.106 | valid_loss: 2.428 | valid_f1_score: 0.690\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 47.21s | train_loss: 1.579 | valid_loss: 2.242 | valid_f1_score: 0.684\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 47.49s | train_loss: 1.235 | valid_loss: 2.286 | valid_f1_score: 0.687\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 48.95s | train_loss: 0.796 | valid_loss: 2.223 | valid_f1_score: 0.715\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 45.99s | train_loss: 0.652 | valid_loss: 2.343 | valid_f1_score: 0.736\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 45.06s | train_loss: 0.563 | valid_loss: 2.347 | valid_f1_score: 0.725\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 45.63s | train_loss: 0.496 | valid_loss: 2.407 | valid_f1_score: 0.717\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▂▂▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▃▆▆▆▇██▇</td></tr><tr><td>valid/batch_loss</td><td>█▃▂▁▁▁▂▂▂</td></tr><tr><td>valid/epoch_loss</td><td>█▃▂▁▁▁▁▁▂</td></tr><tr><td>valid/f1_score</td><td>▁▃▆▆▆▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.50144</td></tr><tr><td>train/epoch_loss</td><td>0.49592</td></tr><tr><td>valid/batch_f1</td><td>0.78965</td></tr><tr><td>valid/batch_loss</td><td>2.65416</td></tr><tr><td>valid/epoch_loss</td><td>2.40749</td></tr><tr><td>valid/f1_score</td><td>0.71702</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">happy-sweep-14</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/ro79lgid\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/ro79lgid</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_190210-ro79lgid\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eywhqzwr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_190931-eywhqzwr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/eywhqzwr\" target=\"_blank\">eager-sweep-15</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 42.67s | train_loss: 12.111 | valid_loss: 4.433 | valid_f1_score: 0.505\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 44.54s | train_loss: 3.127 | valid_loss: 2.904 | valid_f1_score: 0.621\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 45.37s | train_loss: 2.088 | valid_loss: 2.370 | valid_f1_score: 0.677\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 45.49s | train_loss: 1.602 | valid_loss: 2.242 | valid_f1_score: 0.680\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 45.55s | train_loss: 1.232 | valid_loss: 2.142 | valid_f1_score: 0.712\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 45.40s | train_loss: 1.020 | valid_loss: 2.342 | valid_f1_score: 0.703\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 46.43s | train_loss: 0.654 | valid_loss: 2.265 | valid_f1_score: 0.723\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 46.36s | train_loss: 0.526 | valid_loss: 2.460 | valid_f1_score: 0.721\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 46.43s | train_loss: 0.459 | valid_loss: 2.598 | valid_f1_score: 0.716\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▂▂▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▅▇▇█▇███</td></tr><tr><td>valid/batch_loss</td><td>█▃▂▁▁▂▁▂▂</td></tr><tr><td>valid/epoch_loss</td><td>█▃▂▁▁▂▁▂▂</td></tr><tr><td>valid/f1_score</td><td>▁▅▇▇█▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.467</td></tr><tr><td>train/epoch_loss</td><td>0.45877</td></tr><tr><td>valid/batch_f1</td><td>0.78666</td></tr><tr><td>valid/batch_loss</td><td>2.86782</td></tr><tr><td>valid/epoch_loss</td><td>2.5983</td></tr><tr><td>valid/f1_score</td><td>0.71604</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eager-sweep-15</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/eywhqzwr\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/eywhqzwr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_190931-eywhqzwr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 910lgtxi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220419_191632-910lgtxi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/910lgtxi\" target=\"_blank\">mild-sweep-16</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/sweeps/k1ep9l3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/12 | time: 46.77s | train_loss: 12.236 | valid_loss: 4.042 | valid_f1_score: 0.567\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/12 | time: 49.72s | train_loss: 3.038 | valid_loss: 2.716 | valid_f1_score: 0.633\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/12 | time: 48.69s | train_loss: 2.106 | valid_loss: 2.339 | valid_f1_score: 0.677\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.003000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/12 | time: 48.21s | train_loss: 1.565 | valid_loss: 2.169 | valid_f1_score: 0.695\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/12 | time: 47.50s | train_loss: 0.996 | valid_loss: 2.181 | valid_f1_score: 0.723\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/12 | time: 47.27s | train_loss: 0.803 | valid_loss: 2.063 | valid_f1_score: 0.720\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/12 | time: 48.20s | train_loss: 0.690 | valid_loss: 2.178 | valid_f1_score: 0.716\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "LR: 0.000900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/12 | time: 46.83s | train_loss: 0.600 | valid_loss: 2.343 | valid_f1_score: 0.716\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000270\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/12 | time: 47.25s | train_loss: 0.471 | valid_loss: 2.498 | valid_f1_score: 0.733\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LR: 0.000270\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/12 | time: 46.31s | train_loss: 0.420 | valid_loss: 2.550 | valid_f1_score: 0.720\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▄▆▆▇▇▇▇█▇</td></tr><tr><td>valid/batch_loss</td><td>█▃▂▁▁▁▁▂▃▃</td></tr><tr><td>valid/epoch_loss</td><td>█▃▂▁▁▁▁▂▃▃</td></tr><tr><td>valid/f1_score</td><td>▁▄▆▆█▇▇▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>0.42795</td></tr><tr><td>train/epoch_loss</td><td>0.41979</td></tr><tr><td>valid/batch_f1</td><td>0.79373</td></tr><tr><td>valid/batch_loss</td><td>2.77466</td></tr><tr><td>valid/epoch_loss</td><td>2.55026</td></tr><tr><td>valid/f1_score</td><td>0.72038</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">mild-sweep-16</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_last/runs/910lgtxi\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_last/runs/910lgtxi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220419_191632-910lgtxi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, start, count=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K_P9EgYbndTz",
   "metadata": {
    "id": "K_P9EgYbndTz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bfa54d6",
   "metadata": {
    "id": "9bfa54d6"
   },
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611625ac",
   "metadata": {
    "id": "611625ac"
   },
   "outputs": [],
   "source": [
    "model_save_path = \"../../model/my_model_515.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bFbjB3M_cNPq",
   "metadata": {
    "id": "bFbjB3M_cNPq"
   },
   "outputs": [],
   "source": [
    "model_save_path = \"/content/drive/MyDrive/Colab Notebooks/NLP/nlp2022-hw1/model/my_model_497.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acbdb15",
   "metadata": {
    "id": "3acbdb15"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b365d",
   "metadata": {
    "id": "5e5b365d"
   },
   "source": [
    "```Python\n",
    "POS\n",
    "\n",
    "h_params = {\n",
    "    'vocab_size': len(vocab),\n",
    "    'vocab_size_pos': len(pos2idx),\n",
    "    'embed_dim': 300,\n",
    "    'embed_dim_pos': 50,\n",
    "    'hidden_dim': 16,\n",
    "    'num_classes': len(lab2idx),\n",
    "    'embeddings': pretrained_embeddings,\n",
    "    'bidirectional': True,\n",
    "    'num_layers': 3,\n",
    "    'dropout': 0.5,\n",
    "    'use_crf': False,  \n",
    "}\n",
    "\n",
    "epochs = 10 # number of epochs\n",
    "lr = 0.001  # learning rate\n",
    "bacth_size = 32 # batch size for training\n",
    "clipping = 0.5 \n",
    "\n",
    "optimizer = Adam\n",
    "\n",
    "F1 = 0.441\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18165c7",
   "metadata": {
    "id": "d18165c7"
   },
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd42921",
   "metadata": {
    "id": "7fd42921"
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(model_save_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1f49e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1649664049796,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "a1a1f49e",
    "outputId": "be27db6d-0121-49e5-fa0f-c2454eac3e35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NER_POS_Classifier(\n",
       "  (embeddings): Embedding(10000, 300, padding_idx=0)\n",
       "  (lstm): LSTM(300, 300, num_layers=3, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (embeddings_pos): Embedding(18, 100, padding_idx=0)\n",
       "  (lstm_pos): LSTM(100, 300, num_layers=3, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (linear_pos): Linear(in_features=600, out_features=600, bias=True)\n",
       "  (linear_word): Linear(in_features=600, out_features=600, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (concat): Linear(in_features=1200, out_features=600, bias=True)\n",
       "  (concat2): Linear(in_features=600, out_features=600, bias=True)\n",
       "  (concat3): Linear(in_features=600, out_features=600, bias=True)\n",
       "  (fc1): Linear(in_features=600, out_features=300, bias=True)\n",
       "  (fc2): Linear(in_features=300, out_features=150, bias=True)\n",
       "  (fc3): Linear(in_features=150, out_features=150, bias=True)\n",
       "  (classifier): Linear(in_features=150, out_features=14, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a3684",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1371,
     "status": "ok",
     "timestamp": 1649663315183,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "ce3a3684",
    "outputId": "9aafbd1c-265c-4248-e0db-c39448e8d5ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4595238095238095"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from seqeval.metrics import f1_score, accuracy_score, classification_report, precision_score, recall_score, performance_measure\n",
    "\n",
    "valid_eval = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "viterbi_list = []\n",
    "\n",
    "\n",
    "for (labels, features, pos_features) in valid_eval:\n",
    "    predictions = model(features, pos_features)\n",
    "    \n",
    "    # This happens in training\n",
    "    viterbi_mask = labels != lab2idx[pad_token]\n",
    "    viterbi_pred = flat_list(model.crf.viterbi_decode(predictions, mask=viterbi_mask))\n",
    "    \n",
    "    labels = labels.view(-1)\n",
    "    predictions = predictions.view(-1, predictions.shape[-1])\n",
    "    \n",
    "    # The following happend in compute loss\n",
    "    mask = labels != lab2idx[pad_token]\n",
    "    labels = labels[mask].tolist()\n",
    "\n",
    "    y_true = [idx2lab[l] for l in labels]\n",
    "    y_true_list.append(y_true)\n",
    "    \n",
    "    viterbi_pred_labels = [idx2lab[l] for l in viterbi_pred]\n",
    "    viterbi_list.append(viterbi_pred_labels)\n",
    "        \n",
    "    predictions = predictions.argmax(1)\n",
    "    predictions = predictions[mask].tolist()\n",
    "    \n",
    "    y_pred = [idx2lab[l] for l in predictions]\n",
    "    y_pred_list.append(y_pred)\n",
    "        \n",
    "print(f\"Viterbi: {f1_score(y_true_list, viterbi_list, average='macro')}\")\n",
    "print(f\"Argamax: {f1_score(y_true_list, y_pred_list, average='macro')}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true_list, viterbi_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca5f2bb",
   "metadata": {
    "id": "9ca5f2bb"
   },
   "outputs": [],
   "source": [
    "for idx, sentence in enumerate(valid_sentences):\n",
    "    print(\"Sentence True Pred Viterbi\")\n",
    "    for i_token, token in enumerate(sentence):\n",
    "        print(token, valid_labels[idx][i_token], y_pred_list[idx][i_token], viterbi_list[idx][i_token])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5213be",
   "metadata": {
    "id": "5a5213be"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pretty_confusion_matrix import pp_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(flat_list(y_true_list), flat_list(viterbi_list), labels=labels)\n",
    "\n",
    "# get pandas dataframe\n",
    "df_cm = pd.DataFrame(cf_matrix, index = [i for i in labels],\n",
    "                     columns = [i for i in labels])\n",
    "# colormap: see this and choose your more dear\n",
    "cmap = 'PuRd'\n",
    "# GnBu, YlGnBu\n",
    "pp_matrix(df_cm, cmap=\"cividis\", figsize=(13,8), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f91565",
   "metadata": {
    "id": "62f91565"
   },
   "source": [
    "# With POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a787ba",
   "metadata": {
    "id": "f4a787ba"
   },
   "outputs": [],
   "source": [
    "class NER_Dataset(Dataset):\n",
    "    def __init__(self, sentences, sentences_labels, sentences_pos=None, sentences_dep=None):\n",
    "        \n",
    "        assert len(sentences) == len(sentences_labels), \\\n",
    "                    \"Inputs must be of the same length\"\n",
    "        \n",
    "#         self.data = []\n",
    "        \n",
    "        self.sentences = sentences\n",
    "        self.labels = sentences_labels\n",
    "        \n",
    "        self.sentences_lengths = [len(s) for s in sentences]\n",
    "            \n",
    "        self.Y = self._from_sequence_to_idx(sentences_labels, lab2idx, pad_token)\n",
    "        self.X = self._from_sequence_to_idx(sentences, vocab, pad_token, unk_token)\n",
    "        \n",
    "#         self.data = list(zip(self.Y, self.X, self.sentences_lengths))\n",
    "        \n",
    "        # POS\n",
    "        if sentences_pos is not None:\n",
    "\n",
    "            assert len(sentences) == len(sentences_pos), \\\n",
    "                    \"Inputs must be of the same length\"\n",
    "            \n",
    "            \n",
    "            self.pos = sentences_pos\n",
    "            self.X_pos = self._from_sequence_to_idx(sentences_pos, pos2idx, pad_token)\n",
    "            \n",
    "#             self.data = list(zip(self.Y, self.X, self.sentences_lengths, self.X_pos))\n",
    "            \n",
    "            # Dependencies\n",
    "            if sentences_dep is not None:\n",
    "                assert len(sentences) == len(sentences_dep), \\\n",
    "                    \"Inputs must be of the same length\"\n",
    "                \n",
    "                self.dep = sentences_dep\n",
    "                self.X_dep = self._from_sequence_to_idx(sentences_dep, dep_vocab, pad_token, unk_token)\n",
    "#                 self.data = list(zip(self.Y, self.X, self.sentences_lengths, self.X_pos, self.X_dep))\n",
    "\n",
    "    def _from_sequence_to_idx(self, sequences_list, vocab, pad_token, unk_token = None):\n",
    "        sequences_idx = []\n",
    "        \n",
    "        if unk_token is not None: # For words\n",
    "            for sentence in sequences_list:\n",
    "                sequences_idx.append([vocab.get(token, vocab[unk_token]) for token in sentence])\n",
    "        else: # For labels\n",
    "            for sentence in sequences_list:\n",
    "                sequences_idx.append([vocab.get(token) for token in sentence])\n",
    "        \n",
    "        return sequences_idx    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.Y[idx], self.X[idx], self.sentences_lengths[idx], self.X_pos[idx]\n",
    "#         return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea0ade",
   "metadata": {
    "id": "b4ea0ade"
   },
   "outputs": [],
   "source": [
    "train_dataset = NER_Dataset(train_sentences, train_labels, train_pos)\n",
    "valid_dataset = NER_Dataset(valid_sentences, valid_labels, valid_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1ae5e",
   "metadata": {
    "id": "97f1ae5e",
    "outputId": "1d047c64-f05e-4541-9ae9-7cf5467d4318"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 6, 1],\n",
       " [18, 220, 205, 102, 113, 6, 11206, 4, 8, 144, 6, 2, 257, 212, 2947, 3],\n",
       " 16,\n",
       " [9, 6, 12, 1, 1, 2, 1, 3, 11, 1, 2, 5, 7, 1, 1, 3])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72065c0",
   "metadata": {
    "id": "a72065c0"
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    labels_list = []\n",
    "    features_list = []\n",
    "    pos_features_list = []\n",
    "\n",
    "    labels, features, sentences_lengths, pos_features = zip(*batch)\n",
    "    \n",
    "    sorted_batch = sorted(zip(labels, features, sentences_lengths, pos_features), \n",
    "                          key=lambda p: len(p[0]), reverse=True)\n",
    "    labels, features, sentence_lengths, pos_features = zip(*sorted_batch)\n",
    "        \n",
    "    max_length_in_batch = np.max(sentence_lengths)\n",
    "    \n",
    "    # Pad sentences and labels to the length of the longest sequence in the batch\n",
    "    for idx, feature in enumerate(features):\n",
    "        features_list.append(pad_sequence(feature, max_length_in_batch, vocab[pad_token]))\n",
    "        labels_list.append(pad_sequence(labels[idx], max_length_in_batch, lab2idx[pad_token]))\n",
    "        pos_features_list.append(pad_sequence(pos_features[idx], max_length_in_batch, pos2idx[pad_token]))\n",
    "    \n",
    "\n",
    "    labels_tensor = torch.LongTensor(labels_list).to(device)\n",
    "    features_tensor = torch.LongTensor(features_list).to(device)\n",
    "    pos_features_tensor = torch.LongTensor(pos_features_list).to(device)\n",
    "\n",
    "\n",
    "    return labels_tensor, features_tensor, sentence_lengths, pos_features_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60fe457",
   "metadata": {
    "id": "d60fe457"
   },
   "outputs": [],
   "source": [
    "from TorchCRF import CRF\n",
    "class NER_POS_Classifier(nn.Module):\n",
    "    def __init__(self, h_params):\n",
    "        super().__init__()\n",
    "        \n",
    "        # POS embeddings\n",
    "        self.embeddings_pos = nn.Embedding(h_params['pos_vocab_size'], \n",
    "                                            h_params['pos_embed_dim'],\n",
    "                                            padding_idx=0)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.lstm_pos = nn.LSTM(h_params['pos_embed_dim'], \n",
    "                            h_params['pos_lstm_hidden_dim'], \n",
    "                            bidirectional=h_params['bidirectional'],\n",
    "#                             num_layers=h_params['num_layers'],\n",
    "                            num_layers=2,\n",
    "                            dropout=h_params['dropout'] if h_params['num_layers'] > 1 else 0,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        \n",
    "        pos_lstm_output_dim = h_params['pos_lstm_hidden_dim'] if h_params['bidirectional'] is False \\\n",
    "                                else h_params['pos_lstm_hidden_dim'] * 2\n",
    "        \n",
    "        # Fasttext\n",
    "        self.fast_embeddings = self._from_pretrained_embeddings(h_params['fast_embeddings'],\n",
    "                                                               h_params['vocab_size'],\n",
    "                                                               h_params['fast_embed_dim'],\n",
    "                                                               freeze=h_params['freeze_fast'])\n",
    "            \n",
    "            \n",
    "\n",
    "        # Glove\n",
    "        self.glove_embeddings = self._from_pretrained_embeddings(h_params['glove_embeddings'],\n",
    "                                                            h_params['vocab_size'],\n",
    "                                                            h_params['glove_embed_dim'],\n",
    "                                                            freeze=h_params['freeze_glove'])\n",
    "        \n",
    "        lstm_input_dim = h_params['fast_embed_dim'] + h_params['glove_embed_dim'] + pos_lstm_output_dim\n",
    "        \n",
    "        # LSTM Word embeddings\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, \n",
    "                            h_params['lstm_hidden_dim'], \n",
    "                            bidirectional=h_params['bidirectional'],\n",
    "                            num_layers=h_params['num_layers'],\n",
    "                            dropout=h_params['dropout'] if h_params['num_layers'] > 1 else 0,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        \n",
    "        lstm_output_dim = h_params['lstm_hidden_dim'] if h_params['bidirectional'] is False \\\n",
    "                            else h_params['lstm_hidden_dim'] * 2\n",
    "        \n",
    "        \n",
    "#         self.linear_word = nn.Linear(lstm_output_dim, lstm_output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(h_params['dropout'])  \n",
    "\n",
    "        self.concat = nn.Linear(lstm_output_dim, lstm_output_dim)\n",
    "#         self.fc1 = nn.Linear(lstm_output_dim, lstm_output_dim)\n",
    "\n",
    "        self.classifier = nn.Linear(lstm_output_dim, h_params['num_classes'])\n",
    "        \n",
    "        self.relu = nn.LeakyReLU()\n",
    "        \n",
    "        if h_params['use_crf']:\n",
    "            self.crf = CRF(h_params['num_classes'])\n",
    "\n",
    "        self._init_linear_weights()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, x_lengths, x_pos):\n",
    "        \n",
    "        x_pos = self.embeddings_pos(x_pos)\n",
    "        x_pos = self.dropout(x_pos)\n",
    "\n",
    "        x_pos_dep, _ = self.lstm_pos(x_pos)\n",
    "        \n",
    "        \n",
    "        x_fast = self.fast_embeddings(x)\n",
    "        x_glove = self.glove_embeddings(x)\n",
    "        \n",
    "        x = torch.cat((x_fast, x_glove, x_pos), dim=2)  \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.concat(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        output = self.classifier(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "    def _from_pretrained_embeddings(self, pretrained_embeddings, vocab_size, embed_dim, freeze: bool):\n",
    "        embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        \n",
    "        # Get emebeddings from pretrained ones\n",
    "        embeddings.weight.data.copy_(pretrained_embeddings)\n",
    "        \n",
    "        # Freeze embeddings\n",
    "        embeddings.weight.requires_grad = not freeze \n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    def _init_linear_weights(self):\n",
    "        initrange = 0.5\n",
    "\n",
    "        self.concat.weight.data.uniform_(-initrange, initrange)\n",
    "        self.concat.bias.data.zero_()\n",
    "\n",
    "        \n",
    "        self.classifier.weight.data.uniform_(-initrange, initrange)\n",
    "        self.classifier.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9efe67d",
   "metadata": {
    "id": "b9efe67d"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, h_params, optimizer, criterion, grad_clipping):\n",
    "    model.train()    \n",
    "    running_loss = 0.0\n",
    "    f1_score = 0.0\n",
    "    viterbi_pred = None\n",
    "    \n",
    "    for idx, (labels, features, sentences_lengths, pos_features) in enumerate(dataloader): \n",
    "        # Empty gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        predicted_labels = model(features, sentences_lengths, pos_features)\n",
    "\n",
    "        \n",
    "        if h_params['use_crf']:\n",
    "            mask = (labels != lab2idx[pad_token])\n",
    "            \n",
    "            log_likelihood = model.crf(predicted_labels, labels, mask=mask)\n",
    "            # Predictions\n",
    "            viterbi_pred = flat_list(model.crf.viterbi_decode(predicted_labels, mask=mask))        \n",
    "                \n",
    "                \n",
    "            # The log likelihood is not normalized \n",
    "            # (It is not divided by the batch size and it is negative)\n",
    "            loss = torch.mean(log_likelihood) * -1\n",
    "\n",
    "            predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "            labels = labels.view(-1)\n",
    "            \n",
    "        else:\n",
    "            predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "            labels = labels.view(-1)\n",
    "            loss = criterion(predicted_labels, labels)\n",
    "            \n",
    "\n",
    "         # Backward  \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Clipping to prevent exploding gradients\n",
    "        if grad_clipping is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clipping)\n",
    "        # Update weights \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "#         f1_score += compute_score(predicted_labels, labels, viterbi_pred)\n",
    "            \n",
    "    # Loss at the end of the epoch \n",
    "    return running_loss/len(dataloader), f1_score/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf82787",
   "metadata": {
    "id": "4cf82787"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, h_params, criterion):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    f1_score = 0.0\n",
    "    viterbi_pred = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (labels, features, sentences_lengths, pos_features) in enumerate(dataloader):\n",
    "            predicted_labels = model(features, sentences_lengths, pos_features)\n",
    "            \n",
    "            if h_params['use_crf']:\n",
    "                mask = (labels != lab2idx[pad_token])\n",
    "                log_likelihood = model.crf(predicted_labels, labels, mask=mask) \n",
    "                \n",
    "                viterbi_pred = flat_list(model.crf.viterbi_decode(predicted_labels, mask=mask))        \n",
    "                \n",
    "                \n",
    "                # The log likelihood is not normalized \n",
    "                # (It is not divided by the batch size and it is negative)\n",
    "                loss = torch.mean(log_likelihood) * -1\n",
    "\n",
    "                predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "                labels = labels.view(-1)\n",
    "                \n",
    "\n",
    "            else:\n",
    "                predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "                labels = labels.view(-1)\n",
    "                loss = criterion(predicted_labels, labels)\n",
    "                \n",
    "               \n",
    "            valid_loss += loss.item()\n",
    "            f1_score += compute_score(predicted_labels, labels, viterbi_pred)\n",
    "            \n",
    "    return valid_loss/len(dataloader), f1_score/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9f5e9",
   "metadata": {
    "id": "8bc9f5e9"
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }\n",
    "\n",
    "metric = {\n",
    "    'name': 'valid/f1_score',\n",
    "    'goal': 'maximize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'lstm_hidden_dim': {\n",
    "        'values': [128, 256, 512]\n",
    "        },\n",
    "\n",
    "#     'dropout': {\n",
    "#         'distribution': 'uniform',\n",
    "#         'min': 0.4,\n",
    "#         'max': 0.6,\n",
    "#     },\n",
    "    'dropout': {\n",
    "        \"values\": [.3, .4, .5]\n",
    "    },\n",
    "    \n",
    "    'lr': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.0008,\n",
    "        'max': 0.009,\n",
    "      },\n",
    "\n",
    "    \n",
    "    'grad_clipping': {\n",
    "         # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.5,\n",
    "        'max': 2.5\n",
    "    },\n",
    "    \n",
    "    \"batch_size\": {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "\n",
    "    \"epochs\": {\n",
    "        'values': [15]\n",
    "    },\n",
    "\n",
    "    # \"freeze_fast\": {\n",
    "    #     \"values\": [True, False]\n",
    "    # },\n",
    "    # \"freeze_glove\": {\n",
    "    #     \"values\": [True, False]\n",
    "    # },\n",
    "    \"freeze_fast\": {\n",
    "        \"values\": [True, False]\n",
    "    },\n",
    "    \"freeze_glove\": {\n",
    "        \"values\": [True, False]\n",
    "    },\n",
    "\n",
    "    \"sceduler_step\": {\n",
    "        'distribution': 'int_uniform',\n",
    "        'min': 5,\n",
    "        'max': 7\n",
    "    },\n",
    "    \"sceduler_gamma\": {\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.1,\n",
    "        'max': 0.6\n",
    "    },\n",
    "    \n",
    "    \"num_layers\": {\n",
    "        \"values\": [2,3, 4]\n",
    "    },\n",
    "    'pos_lstm_hidden_dim': {\n",
    "        'values': [128, 256, 512]\n",
    "    },\n",
    "    'pos_embed_dim': {\n",
    "        'values': [50, 100, 150]\n",
    "    },\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c05f0",
   "metadata": {
    "id": "222c05f0",
    "outputId": "4171c339-55c3-465c-dcab-3671522f92da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: jrfqny0i\n",
      "Sweep URL: https://wandb.ai/florin-ml/NLP_HW01_pos/sweeps/jrfqny0i\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"NLP_HW01_pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73e736",
   "metadata": {
    "id": "fb73e736"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "def start():\n",
    "\n",
    "    wandb.init(project=\"NLP_HW01_dep\")\n",
    "    config = wandb.config\n",
    "\n",
    "    h_params = {\n",
    "        'pos_vocab_size': len(pos2idx),\n",
    "        'pos_embed_dim': config.pos_embed_dim,\n",
    "        'pos_lstm_hidden_dim': config.pos_lstm_hidden_dim,\n",
    "        'vocab_size': len(vocab),\n",
    "        'fast_embed_dim': 300,\n",
    "        'freeze_fast': config.freeze_fast,\n",
    "        'glove_embed_dim': 100,\n",
    "        'freeze_glove': config.freeze_glove,\n",
    "        'lstm_hidden_dim': config.lstm_hidden_dim, \n",
    "        'num_classes': len(lab2idx),\n",
    "        'fast_embeddings': fast_pretrained_embeddings,\n",
    "        'glove_embeddings': glove_pretrained_embeddings,\n",
    "        'bidirectional': True,\n",
    "        'num_layers': config.num_layers,\n",
    "        'dropout': config.dropout,\n",
    "        'use_crf': True,  # set to true to test with the Conditional Random Field\n",
    "    }\n",
    "\n",
    "    model = NER_POS_Classifier(h_params).to(device)\n",
    "\n",
    "    # Hyperparameters\n",
    "    epochs = config.epochs # number of epochs\n",
    "    lr = config.lr # learning rate .005\n",
    "    bacth_size = config.batch_size # batch size for training 64\n",
    "    grad_clipping = config.grad_clipping # for clipping gradients         \n",
    "        \n",
    "                                                # ignore the padding class\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=lab2idx[pad_token]).to(device)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.95)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#     scheduler = None\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config['sceduler_step'], gamma=config['sceduler_gamma'])\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[6, 9, 13, 20, 22], gamma=0.1)\n",
    "    # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.002, max_lr=0.01)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=bacth_size, \n",
    "                                collate_fn=collate_batch, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=bacth_size, \n",
    "                                collate_fn=collate_batch, shuffle=False)\n",
    "\n",
    "    histories = train_model(model, train_dataloader, valid_dataloader, h_params, \n",
    "                            optimizer, criterion, scheduler, grad_clipping, epochs,\n",
    "                            early_stopping=True, early_stopping_mode=\"max\", \n",
    "                            early_stopping_patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f1d3bb",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      ""
     ]
    },
    "id": "92f1d3bb",
    "outputId": "391ed6fd-8053-4775-af86-421e189b6ad8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7bk7q85s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 1.2277695981149055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0012255320716480463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpos_embed_dim: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpos_lstm_hidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.5071660951645122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>H:\\My Drive\\Colab Notebooks\\NLP\\nlp2022-hw1\\hw1\\stud\\wandb\\run-20220417_191827-7bk7q85s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_pos/runs/7bk7q85s\" target=\"_blank\">dry-sweep-2</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_pos\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_pos/sweeps/jrfqny0i\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_pos/sweeps/jrfqny0i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dry-sweep-2</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_pos/runs/7bk7q85s\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_pos/runs/7bk7q85s</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220417_191827-7bk7q85s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 7bk7q85s errored: RuntimeError('input.size(-1) must be equal to input_size. Expected 912, got 450')\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, start, count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b05209",
   "metadata": {
    "id": "b6b05209"
   },
   "source": [
    "# With DEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f9a39ef",
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1650264362914,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "3f9a39ef"
   },
   "outputs": [],
   "source": [
    "class NER_DEP_Dataset(Dataset):\n",
    "    def __init__(self, sentences, sentences_labels, sentences_heads,  sentences_dep):\n",
    "\n",
    "        assert len(sentences) == len(sentences_labels) == len(sentences_dep), \\\n",
    "                \"Inputs must be of the same length\"\n",
    "        \n",
    "        self.sentences = sentences\n",
    "        self.labels = sentences_labels\n",
    "        self.heads = sentences_heads\n",
    "        self.dep = sentences_dep\n",
    "        self.sentences_lengths = [len(s) for s in sentences]\n",
    "\n",
    "        \n",
    "        self.Y = self._from_sequence_to_idx(sentences_labels, lab2idx, pad_token)\n",
    "        self.X = self._from_sequence_to_idx(sentences, vocab, pad_token, unk_token)\n",
    "        \n",
    "        # DEP\n",
    "        self.X_heads = self._from_sequence_to_idx(sentences_heads, vocab, pad_token, unk_token)\n",
    "        self.X_dep = self._from_sequence_to_idx(sentences_dep, dep_vocab, pad_token, unk_token)\n",
    "    \n",
    "    def _from_sequence_to_idx(self, sequences_list, vocab, pad_token, unk_token = None):\n",
    "        sequences_idx = []\n",
    "        \n",
    "        if unk_token is not None: # For words\n",
    "            for sentence in sequences_list:\n",
    "                sequences_idx.append([vocab.get(token, vocab[unk_token]) for token in sentence])\n",
    "        else: # For labels\n",
    "            for sentence in sequences_list:\n",
    "                sequences_idx.append([vocab.get(token) for token in sentence])\n",
    "        \n",
    "        return sequences_idx    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.Y[idx], self.X[idx], self.sentences_lengths[idx], self.X_heads[idx], self.X_dep[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "027eb94f",
   "metadata": {
    "executionInfo": {
     "elapsed": 580,
     "status": "ok",
     "timestamp": 1650264365043,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "027eb94f"
   },
   "outputs": [],
   "source": [
    "train_dataset = NER_DEP_Dataset(train_sentences, train_labels, train_heads, train_dep)\n",
    "valid_dataset = NER_DEP_Dataset(valid_sentences, valid_labels, valid_heads, valid_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dd3c034",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1650264365915,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "8dd3c034"
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    labels_list = []\n",
    "    features_list = []\n",
    "    heads_features_list = []\n",
    "    dep_features_list = []\n",
    "\n",
    "    labels, features, sentences_lengths, heads_features, dep_features = zip(*batch)\n",
    "    \n",
    "    sorted_batch = sorted(zip(labels, features, sentences_lengths, heads_features, dep_features), \n",
    "                          key=lambda p: len(p[0]), reverse=True)\n",
    "    labels, features, sentence_lengths, heads_features, dep_features = zip(*sorted_batch)\n",
    "        \n",
    "    max_length_in_batch = np.max(sentence_lengths)\n",
    "    \n",
    "    # Pad sentences and labels to the length of the longest sequence in the batch\n",
    "    for idx, feature in enumerate(features):\n",
    "        features_list.append(pad_sequence(feature, max_length_in_batch, vocab[pad_token]))\n",
    "        labels_list.append(pad_sequence(labels[idx], max_length_in_batch, lab2idx[pad_token]))\n",
    "        heads_features_list.append(pad_sequence(heads_features[idx], max_length_in_batch, vocab[pad_token]))\n",
    "        dep_features_list.append(pad_sequence(dep_features[idx], max_length_in_batch, dep_vocab[pad_token]))\n",
    "        \n",
    "\n",
    "    labels_tensor = torch.LongTensor(labels_list).to(device)\n",
    "    features_tensor = torch.LongTensor(features_list).to(device)\n",
    "    dep_features_tensor = torch.LongTensor(dep_features_list).to(device)\n",
    "    heads_features_tensor = torch.LongTensor(heads_features_list).to(device)\n",
    "   \n",
    "\n",
    "    return labels_tensor, features_tensor, sentence_lengths, heads_features_tensor, dep_features_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "95a7866c",
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1650274655822,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "95a7866c"
   },
   "outputs": [],
   "source": [
    "from TorchCRF import CRF\n",
    "class NER_DEP_Classifier(nn.Module):\n",
    "    def __init__(self, h_params):\n",
    "        super().__init__()\n",
    "\n",
    "        # Dependency embeddings\n",
    "        self.embeddings_dep = nn.Embedding(h_params['dep_vocab_size'], \n",
    "                                            h_params['dep_embed_dim'],\n",
    "                                            padding_idx=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         self.lstm_pos_dep = nn.LSTM(h_params['pos_embed_dim'] + h_params['dep_embed_dim'], \n",
    "#                             h_params['pos_dep_lstm_hidden_dim'], \n",
    "#                             bidirectional=h_params['bidirectional'],\n",
    "# #                             num_layers=h_params['num_layers'],\n",
    "#                             num_layers=2,\n",
    "#                             dropout=h_params['dropout'] if h_params['num_layers'] > 1 else 0,\n",
    "#                             batch_first=True)\n",
    "        \n",
    "        \n",
    "#         pos_dep_lstm_output_dim = h_params['pos_dep_lstm_hidden_dim'] if h_params['bidirectional'] is False \\\n",
    "#                                 else h_params['pos_dep_lstm_hidden_dim'] * 2\n",
    "        \n",
    "        # Fasttext\n",
    "        # self.fast_embeddings = self._from_pretrained_embeddings(h_params['fast_embeddings'],\n",
    "        #                                                        h_params['vocab_size'],\n",
    "        #                                                        h_params['fast_embed_dim'],\n",
    "        #                                                        freeze=h_params['freeze_fast'])\n",
    "            \n",
    "            \n",
    "\n",
    "        # Glove\n",
    "        # self.glove_embeddings = self._from_pretrained_embeddings(h_params['glove_embeddings'],\n",
    "        #                                                     h_params['vocab_size'],\n",
    "        #                                                     h_params['glove_embed_dim'],\n",
    "        #                                                     freeze=h_params['freeze_glove'])\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(h_params['vocab_size'], \n",
    "                                            h_params['word_embed_dim'],\n",
    "                                            padding_idx=0)\n",
    "        \n",
    "#         lstm_input_dim = h_params['fast_embed_dim'] + h_params['glove_embed_dim'] + h_params['dep_embed_dim']\n",
    "\n",
    "        # lstm_input_dim = h_params['fast_embed_dim'] * 2 + h_params['glove_embed_dim'] * 2 + h_params['dep_embed_dim']\n",
    "        lstm_input_dim = h_params['word_embed_dim'] * 2 + h_params['dep_embed_dim']\n",
    "        \n",
    "        # LSTM Word embeddings\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, \n",
    "                            h_params['lstm_hidden_dim'], \n",
    "                            bidirectional=h_params['bidirectional'],\n",
    "                            num_layers=h_params['num_layers'],\n",
    "                            dropout=h_params['dropout'] if h_params['num_layers'] > 1 else 0,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        \n",
    "        lstm_output_dim = h_params['lstm_hidden_dim'] if h_params['bidirectional'] is False \\\n",
    "                            else h_params['lstm_hidden_dim'] * 2\n",
    "        \n",
    "        \n",
    "#         self.linear_word = nn.Linear(lstm_output_dim, lstm_output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(h_params['dropout'])  \n",
    "\n",
    "        self.concat = nn.Linear(lstm_output_dim, lstm_output_dim)\n",
    "        # self.fc1 = nn.Linear(lstm_output_dim, lstm_output_dim)\n",
    "\n",
    "        self.classifier = nn.Linear(lstm_output_dim, h_params['num_classes'])\n",
    "        \n",
    "        self.relu = nn.LeakyReLU()\n",
    "        \n",
    "        if h_params['use_crf']:\n",
    "            self.crf = CRF(h_params['num_classes'])\n",
    "\n",
    "        self._init_linear_weights()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, x_lengths, x_heads, x_dep):\n",
    "        \n",
    "        # x_fast = self.fast_embeddings(x)\n",
    "        # x_glove = self.glove_embeddings(x)\n",
    "        \n",
    "        # x_fast_heads = self.fast_embeddings(x_heads)\n",
    "        # x_glove_heads = self.glove_embeddings(x_heads)\n",
    "        \n",
    "        x_word = self.word_embeddings(x)\n",
    "        x_heads = self.word_embeddings(x_heads)\n",
    "        x_dep = self.embeddings_dep(x_dep)\n",
    "        \n",
    "        \n",
    "        x = torch.cat((x_word, x_heads, x_dep), dim=2)  \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.concat(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.fc1(x)\n",
    "        # x = self.relu(x)\n",
    "\n",
    "        output = self.classifier(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "    def _from_pretrained_embeddings(self, pretrained_embeddings, vocab_size, embed_dim, freeze: bool):\n",
    "        embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        \n",
    "        # Get emebeddings from pretrained ones\n",
    "        embeddings.weight.data.copy_(pretrained_embeddings)\n",
    "        \n",
    "        # Freeze embeddings\n",
    "        embeddings.weight.requires_grad = not freeze \n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    def _init_linear_weights(self):\n",
    "        initrange = 0.5\n",
    "\n",
    "        self.concat.weight.data.uniform_(-initrange, initrange)\n",
    "        self.concat.bias.data.zero_()\n",
    "        # self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "        # self.fc1.bias.data.zero_()\n",
    "\n",
    "        \n",
    "        self.classifier.weight.data.uniform_(-initrange, initrange)\n",
    "        self.classifier.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abffee5c",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1650264383557,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "abffee5c"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, h_params, optimizer, criterion, grad_clipping):\n",
    "    model.train()    \n",
    "    running_loss = 0.0\n",
    "    f1_score = 0.0\n",
    "    viterbi_pred = None\n",
    "    \n",
    "    for idx, (labels, features, sentences_lengths, heads_features, dep_features) in enumerate(dataloader): \n",
    "        # Empty gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        predicted_labels = model(features, sentences_lengths, heads_features, dep_features)\n",
    "\n",
    "        \n",
    "        if h_params['use_crf']:\n",
    "            mask = (labels != lab2idx[pad_token])\n",
    "            \n",
    "            log_likelihood = model.crf(predicted_labels, labels, mask=mask)\n",
    "            # Predictions\n",
    "            viterbi_pred = flat_list(model.crf.viterbi_decode(predicted_labels, mask=mask))        \n",
    "                \n",
    "                \n",
    "            # The log likelihood is not normalized \n",
    "            # (It is not divided by the batch size and it is negative)\n",
    "            loss = torch.mean(log_likelihood) * -1\n",
    "\n",
    "            predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "            labels = labels.view(-1)\n",
    "            \n",
    "        else:\n",
    "            predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "            labels = labels.view(-1)\n",
    "            loss = criterion(predicted_labels, labels)\n",
    "            \n",
    "\n",
    "         # Backward  \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Clipping to prevent exploding gradients\n",
    "        if grad_clipping is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clipping)\n",
    "        # Update weights \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "#         f1_score += compute_score(predicted_labels, labels, viterbi_pred)\n",
    "            \n",
    "        if idx > 0 and idx % 50 == 0:\n",
    "            metrics = {\"train/batch_loss\": running_loss/idx}\n",
    "            wandb.log(metrics)\n",
    "            \n",
    "    # Loss at the end of the epoch \n",
    "    return running_loss/len(dataloader), f1_score/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44e19117",
   "metadata": {
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1650264386243,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "44e19117"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, h_params, criterion):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    f1_score = 0.0\n",
    "    viterbi_pred = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (labels, features, sentences_lengths, heads_features, dep_features) in enumerate(dataloader):\n",
    "            predicted_labels = model(features, sentences_lengths, heads_features, dep_features)\n",
    "            \n",
    "            if h_params['use_crf']:\n",
    "                mask = (labels != lab2idx[pad_token])\n",
    "                log_likelihood = model.crf(predicted_labels, labels, mask=mask) \n",
    "                \n",
    "                viterbi_pred = flat_list(model.crf.viterbi_decode(predicted_labels, mask=mask))        \n",
    "                \n",
    "                \n",
    "                # The log likelihood is not normalized \n",
    "                # (It is not divided by the batch size and it is negative)\n",
    "                loss = torch.mean(log_likelihood) * -1\n",
    "\n",
    "                predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "                labels = labels.view(-1)\n",
    "                \n",
    "\n",
    "            else:\n",
    "                predicted_labels = predicted_labels.view(-1, predicted_labels.shape[-1])\n",
    "                labels = labels.view(-1)\n",
    "                loss = criterion(predicted_labels, labels)\n",
    "                \n",
    "               \n",
    "            valid_loss += loss.item()\n",
    "            f1_score += compute_score(predicted_labels, labels, viterbi_pred)\n",
    "            \n",
    "            if idx > 0 and idx % 10 == 0:\n",
    "                metrics = {\"valid/batch_loss\": valid_loss/idx, \n",
    "                            \"valid/batch_f1\": f1_score/idx}\n",
    "                wandb.log(metrics)\n",
    "            \n",
    "    return valid_loss/len(dataloader), f1_score/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9bae522c",
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1650275504282,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "9bae522c"
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }\n",
    "\n",
    "metric = {\n",
    "    'name': 'valid/f1_score',\n",
    "    'goal': 'maximize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'lstm_hidden_dim': {\n",
    "        'values': [128, 256, 512]\n",
    "        },\n",
    "\n",
    "#     'dropout': {\n",
    "#         'distribution': 'uniform',\n",
    "#         'min': 0.4,\n",
    "#         'max': 0.6,\n",
    "#     },\n",
    "    'dropout': {\n",
    "        \"values\": [.4, .5]\n",
    "    },\n",
    "    \n",
    "    'lr': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.003,\n",
    "        'max': 0.05,\n",
    "      },\n",
    "\n",
    "    \n",
    "    'grad_clipping': {\n",
    "         # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.5,\n",
    "        'max': 2.5\n",
    "    },\n",
    "    \n",
    "    \"batch_size\": {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "\n",
    "    \"epochs\": {\n",
    "        'values': [15]\n",
    "    },\n",
    "\n",
    "    # \"freeze_fast\": {\n",
    "    #     \"values\": [True, False]\n",
    "    # },\n",
    "    # \"freeze_glove\": {\n",
    "    #     \"values\": [True, False]\n",
    "    # },\n",
    "    \"freeze_fast\": {\n",
    "        \"values\": [True, False]\n",
    "    },\n",
    "    \"freeze_glove\": {\n",
    "        \"values\": [True]\n",
    "    },\n",
    "\n",
    "    \"sceduler_step\": {\n",
    "        'distribution': 'int_uniform',\n",
    "        'min': 4,\n",
    "        'max': 7\n",
    "    },\n",
    "    \"sceduler_gamma\": {\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.1,\n",
    "        'max': 0.6\n",
    "    },\n",
    "    \n",
    "    \"num_layers\": {\n",
    "        \"values\": [2,3]\n",
    "    },\n",
    "    # 'pos_dep_lstm_hidden_dim': {\n",
    "    #     'values': [128, 256, 512]\n",
    "    # },\n",
    "    # 'pos_embed_dim': {\n",
    "    #     'values': [50, 100, 150]\n",
    "    # },\n",
    "    'dep_embed_dim': {\n",
    "        'values': [50, 80, 100]\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "766c78ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2157,
     "status": "ok",
     "timestamp": 1650275509348,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "766c78ba",
    "outputId": "e2e35525-78b7-4498-c889-c1f46a23d7cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: xxxaknqt\n",
      "Sweep URL: https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"NLP_HW01_heads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5e66cc18",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1650275509348,
     "user": {
      "displayName": "Florin Cuconasu",
      "userId": "13345521608196528334"
     },
     "user_tz": -120
    },
    "id": "5e66cc18"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "def start():\n",
    "\n",
    "    wandb.init(project=\"NLP_HW01_heads\")\n",
    "    config = wandb.config\n",
    "\n",
    "    h_params = {\n",
    "        # 'pos_vocab_size': len(pos2idx),\n",
    "        # 'pos_embed_dim': config.pos_embed_dim,\n",
    "        'word_embed_dim': 300,\n",
    "        'dep_vocab_size': len(dep_vocab),\n",
    "        'dep_embed_dim': config.dep_embed_dim,\n",
    "        # 'pos_dep_lstm_hidden_dim': 200,\n",
    "        'vocab_size': len(vocab),\n",
    "        'fast_embed_dim': 300,\n",
    "        'freeze_fast': config.freeze_fast,\n",
    "        'glove_embed_dim': 100,\n",
    "        'freeze_glove': config.freeze_glove,\n",
    "        'lstm_hidden_dim': config.lstm_hidden_dim, \n",
    "        'num_classes': len(lab2idx),\n",
    "        'fast_embeddings': fast_pretrained_embeddings,\n",
    "        'glove_embeddings': glove_pretrained_embeddings,\n",
    "        'bidirectional': True,\n",
    "        'num_layers': config.num_layers,\n",
    "        'dropout': config.dropout,\n",
    "        'use_crf': True,  # set to true to test with the Conditional Random Field\n",
    "    }\n",
    "\n",
    "    model = NER_DEP_Classifier(h_params).to(device)\n",
    "\n",
    "    # Hyperparameters\n",
    "    epochs = config.epochs # number of epochs\n",
    "    lr = config.lr # learning rate .005\n",
    "    bacth_size = config.batch_size # batch size for training 64\n",
    "    grad_clipping = config.grad_clipping # for clipping gradients         \n",
    "        \n",
    "                                                # ignore the padding class\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=lab2idx[pad_token]).to(device)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.95)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#     scheduler = None\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config['sceduler_step'], gamma=config['sceduler_gamma'])\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[6, 9, 13, 20, 22], gamma=0.1)\n",
    "    # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.002, max_lr=0.01)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=bacth_size, \n",
    "                                collate_fn=collate_batch, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=bacth_size, \n",
    "                                collate_fn=collate_batch, shuffle=False)\n",
    "\n",
    "    histories = train_model(model, train_dataloader, valid_dataloader, h_params, \n",
    "                            optimizer, criterion, scheduler, grad_clipping, epochs,\n",
    "                            early_stopping=True, early_stopping_mode=\"max\", \n",
    "                            early_stopping_patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d3b0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "55247454d83d4a29befd378f8ccef310",
      "085358ef5fe94f46958f56322362aa77",
      "91c8a00d9b014d738ba7082a82e46923",
      "f504020f277847a69aa89550e75383d1",
      "c5dd2e71f7054899a42ede86fc8162ab",
      "6663c7c9f19b45cba7abdbc8773754da",
      "b372f722d1c04eb79518b390cb5f510d",
      "d72888ddbbf149dd93235230f4ec6eaa",
      "9c18ca217b224f43ad6ba0f63114decb",
      "13e27c7469364ed3b14ad1b33aa75755",
      "d592240840f7454ea25b29dd995f1eb9",
      "6bf2e7643b05436fb1fee8f7ed900e46",
      "607a98df57ff44e4ab9abeeeb86d13bc",
      "da1e332bdaef4af998bae23efae79e0d",
      "f758e4a169034f15a340d0f8c9dd59df",
      "79531487a4bd4b98865e3cf159ea6107",
      "637e90c0090c42db9759b3897e6dc147",
      "bc571ca9ee8d45fb92b57c1506159bb6",
      "8a28c8cd41fd4622a481aa7aef1361de",
      "eaa9f19f204149c6b0eec47cd5c6ea1f",
      "49c086a2d5834afa84f775ced2097406",
      "5e59840764f04c11924d0600df775241",
      "83deb34788974b4abf97f4d54f9d311d",
      "dc6458adeb6a4a30bebba3308ae0fe06",
      "70f9681c24e94a16a43a127915e4e3f5",
      "6c0c24aa3ef9438fab35161dc5318e5a",
      "6c5e321c94af4b47a8155d4177570599",
      "2f081c5121e14c45af8312216110d06d",
      "a0b0ae43cc5a4ed2b1c66f545f637b95",
      "f790512d21804e279a71f18b1bc234c7",
      "ea79a68050804ff785986b7abb1c5578",
      "7545e720d212447a83ff1cfbc11332e0",
      "1ee7f6774b094df6aa329541ab24ae90",
      "ae55a1e880604ec3a72d24c3a409e46a",
      "46e2560b24a14203b198762df500a6c6",
      "4e736154092a4a9d9b82438e920d28fe",
      "d082108d23f04ee6bb30ff0ae5cf0f0f",
      "a9282b4969f54a15bd60be116d706759",
      "7b820ab64a8843ed9c3c4cf1d56773d0",
      "75cf22f1183b475a8bcb8ede4dd6e123"
     ]
    },
    "id": "ac4d3b0f",
    "outputId": "2c22c269-b0fd-4d6e-bfb9-3a93037d384d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4hob6eiq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdep_embed_dim: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 2.2733687257998825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.02197182725552028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.24717601569619063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220418_095158-4hob6eiq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/runs/4hob6eiq\" target=\"_blank\">feasible-sweep-1</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [0.02197182725552028]\n",
      "After: [0.02197182725552028]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/15 | time: 46.87s | train_loss: 56.061 | valid_loss: 5.026 | valid_f1_score: 0.230\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.02197182725552028]\n",
      "After: [0.02197182725552028]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/15 | time: 47.06s | train_loss: 4.771 | valid_loss: 4.876 | valid_f1_score: 0.290\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.02197182725552028]\n",
      "After: [0.02197182725552028]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/15 | time: 46.38s | train_loss: 4.273 | valid_loss: 4.168 | valid_f1_score: 0.323\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.02197182725552028]\n",
      "After: [0.02197182725552028]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/15 | time: 46.47s | train_loss: 4.017 | valid_loss: 4.240 | valid_f1_score: 0.338\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.02197182725552028]\n",
      "After: [0.0054309087185844705]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/15 | time: 46.36s | train_loss: 3.810 | valid_loss: 3.998 | valid_f1_score: 0.359\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0054309087185844705]\n",
      "After: [0.0054309087185844705]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/15 | time: 46.36s | train_loss: 3.551 | valid_loss: 4.011 | valid_f1_score: 0.398\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0054309087185844705]\n",
      "After: [0.0054309087185844705]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/15 | time: 46.53s | train_loss: 3.423 | valid_loss: 4.052 | valid_f1_score: 0.406\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0054309087185844705]\n",
      "After: [0.0054309087185844705]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/15 | time: 46.41s | train_loss: 3.357 | valid_loss: 3.838 | valid_f1_score: 0.414\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0054309087185844705]\n",
      "After: [0.0054309087185844705]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/15 | time: 46.53s | train_loss: 3.278 | valid_loss: 3.891 | valid_f1_score: 0.418\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0054309087185844705]\n",
      "After: [0.0013423903786694137]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/15 | time: 46.36s | train_loss: 3.190 | valid_loss: 3.767 | valid_f1_score: 0.428\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0013423903786694137]\n",
      "After: [0.0013423903786694137]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  11/15 | time: 46.92s | train_loss: 3.091 | valid_loss: 3.787 | valid_f1_score: 0.440\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0013423903786694137]\n",
      "After: [0.0013423903786694137]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  12/15 | time: 46.52s | train_loss: 3.075 | valid_loss: 3.812 | valid_f1_score: 0.430\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "Before: [0.0013423903786694137]\n",
      "After: [0.0013423903786694137]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  13/15 | time: 46.35s | train_loss: 3.057 | valid_loss: 3.742 | valid_f1_score: 0.438\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0013423903786694137]\n",
      "After: [0.0013423903786694137]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  14/15 | time: 46.31s | train_loss: 3.030 | valid_loss: 3.793 | valid_f1_score: 0.433\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "Before: [0.0013423903786694137]\n",
      "After: [0.00033180670530840627]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  15/15 | time: 46.57s | train_loss: 3.003 | valid_loss: 3.739 | valid_f1_score: 0.434\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55247454d83d4a29befd378f8ccef310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▃▄▅▅▇▇▇▇██████</td></tr><tr><td>valid/batch_loss</td><td>█▇▃▄▂▂▃▂▂▁▁▁▁▁▁</td></tr><tr><td>valid/epoch_loss</td><td>█▇▃▄▂▂▃▂▂▁▁▁▁▁▁</td></tr><tr><td>valid/f1_score</td><td>▁▃▄▅▅▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>3.02769</td></tr><tr><td>train/epoch_loss</td><td>3.00277</td></tr><tr><td>valid/batch_f1</td><td>0.48461</td></tr><tr><td>valid/batch_loss</td><td>4.05628</td></tr><tr><td>valid/epoch_loss</td><td>3.7394</td></tr><tr><td>valid/f1_score</td><td>0.4339</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">feasible-sweep-1</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/runs/4hob6eiq\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_heads/runs/4hob6eiq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220418_095158-4hob6eiq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9obzjvle with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdep_embed_dim: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 1.6456588506393135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0384939920519963\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.1791358344785207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220418_100351-9obzjvle</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/runs/9obzjvle\" target=\"_blank\">crimson-sweep-2</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [0.0384939920519963]\n",
      "After: [0.0384939920519963]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/15 | time: 24.47s | train_loss: 52.246 | valid_loss: 4.903 | valid_f1_score: 0.243\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0384939920519963]\n",
      "After: [0.0384939920519963]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/15 | time: 24.32s | train_loss: 4.868 | valid_loss: 4.663 | valid_f1_score: 0.274\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0384939920519963]\n",
      "After: [0.0384939920519963]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/15 | time: 24.69s | train_loss: 4.522 | valid_loss: 4.632 | valid_f1_score: 0.267\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "Before: [0.0384939920519963]\n",
      "After: [0.0068956533886439]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/15 | time: 25.09s | train_loss: 4.312 | valid_loss: 4.324 | valid_f1_score: 0.303\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0068956533886439]\n",
      "After: [0.0068956533886439]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/15 | time: 25.06s | train_loss: 4.010 | valid_loss: 4.206 | valid_f1_score: 0.328\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0068956533886439]\n",
      "After: [0.0068956533886439]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/15 | time: 24.55s | train_loss: 3.862 | valid_loss: 4.254 | valid_f1_score: 0.357\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0068956533886439]\n",
      "After: [0.0068956533886439]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/15 | time: 24.57s | train_loss: 3.778 | valid_loss: 4.147 | valid_f1_score: 0.354\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "Before: [0.0068956533886439]\n",
      "After: [0.001235258624049364]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/15 | time: 24.45s | train_loss: 3.689 | valid_loss: 4.132 | valid_f1_score: 0.356\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.001235258624049364]\n",
      "After: [0.001235258624049364]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/15 | time: 24.40s | train_loss: 3.586 | valid_loss: 4.015 | valid_f1_score: 0.367\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.001235258624049364]\n",
      "After: [0.001235258624049364]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/15 | time: 24.59s | train_loss: 3.555 | valid_loss: 4.058 | valid_f1_score: 0.367\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c18ca217b224f43ad6ba0f63114decb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/epoch_loss</td><td>█▆▆▃▃▃▂▂▁▁</td></tr><tr><td>valid/f1_score</td><td>▁▃▂▄▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>3.59477</td></tr><tr><td>train/epoch_loss</td><td>3.5546</td></tr><tr><td>valid/epoch_loss</td><td>4.05756</td></tr><tr><td>valid/f1_score</td><td>0.36651</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">crimson-sweep-2</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/runs/9obzjvle\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_heads/runs/9obzjvle</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220418_100351-9obzjvle/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nlp7bii6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdep_embed_dim: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 1.674387667085155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.008020175887470397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.22413838116415755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220418_100810-nlp7bii6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/runs/nlp7bii6\" target=\"_blank\">pious-sweep-3</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [0.008020175887470397]\n",
      "After: [0.008020175887470397]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/15 | time: 46.82s | train_loss: 107.963 | valid_loss: 8.961 | valid_f1_score: 0.150\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.008020175887470397]\n",
      "After: [0.008020175887470397]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/15 | time: 46.38s | train_loss: 7.698 | valid_loss: 5.678 | valid_f1_score: 0.325\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.008020175887470397]\n",
      "After: [0.008020175887470397]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/15 | time: 46.82s | train_loss: 5.053 | valid_loss: 4.440 | valid_f1_score: 0.411\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.008020175887470397]\n",
      "After: [0.008020175887470397]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/15 | time: 46.70s | train_loss: 3.852 | valid_loss: 3.788 | valid_f1_score: 0.464\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.008020175887470397]\n",
      "After: [0.008020175887470397]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/15 | time: 46.47s | train_loss: 3.157 | valid_loss: 3.403 | valid_f1_score: 0.531\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.008020175887470397]\n",
      "After: [0.008020175887470397]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/15 | time: 46.32s | train_loss: 2.696 | valid_loss: 3.364 | valid_f1_score: 0.565\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.008020175887470397]\n",
      "After: [0.0017976292400694253]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/15 | time: 46.43s | train_loss: 2.365 | valid_loss: 3.241 | valid_f1_score: 0.574\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0017976292400694253]\n",
      "After: [0.0017976292400694253]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/15 | time: 46.10s | train_loss: 2.039 | valid_loss: 3.186 | valid_f1_score: 0.584\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0017976292400694253]\n",
      "After: [0.0017976292400694253]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/15 | time: 46.19s | train_loss: 1.893 | valid_loss: 3.071 | valid_f1_score: 0.604\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0017976292400694253]\n",
      "After: [0.0017976292400694253]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/15 | time: 46.14s | train_loss: 1.776 | valid_loss: 3.071 | valid_f1_score: 0.612\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0017976292400694253]\n",
      "After: [0.0017976292400694253]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  11/15 | time: 46.27s | train_loss: 1.726 | valid_loss: 3.158 | valid_f1_score: 0.596\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "Before: [0.0017976292400694253]\n",
      "After: [0.0017976292400694253]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  12/15 | time: 46.05s | train_loss: 1.632 | valid_loss: 3.075 | valid_f1_score: 0.615\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0017976292400694253]\n",
      "After: [0.0017976292400694253]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  13/15 | time: 46.54s | train_loss: 1.577 | valid_loss: 3.199 | valid_f1_score: 0.609\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "Before: [0.0017976292400694253]\n",
      "After: [0.00040291770780251574]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  14/15 | time: 46.25s | train_loss: 1.513 | valid_loss: 3.068 | valid_f1_score: 0.618\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.00040291770780251574]\n",
      "After: [0.00040291770780251574]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  15/15 | time: 46.18s | train_loss: 1.424 | valid_loss: 3.121 | valid_f1_score: 0.620\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637e90c0090c42db9759b3897e6dc147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/epoch_loss</td><td>█▄▃▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/f1_score</td><td>▁▄▅▆▇▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>1.45594</td></tr><tr><td>train/epoch_loss</td><td>1.42387</td></tr><tr><td>valid/epoch_loss</td><td>3.12092</td></tr><tr><td>valid/f1_score</td><td>0.62</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pious-sweep-3</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/runs/nlp7bii6\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_heads/runs/nlp7bii6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220418_100810-nlp7bii6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: op1l9ozv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdep_embed_dim: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.5797313267306425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.02031017708460951\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.39576837427723854\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220418_102000-op1l9ozv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/runs/op1l9ozv\" target=\"_blank\">helpful-sweep-4</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [0.02031017708460951]\n",
      "After: [0.02031017708460951]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/15 | time: 32.47s | train_loss: 7.875 | valid_loss: 4.679 | valid_f1_score: 0.313\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.02031017708460951]\n",
      "After: [0.02031017708460951]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/15 | time: 32.62s | train_loss: 4.508 | valid_loss: 4.136 | valid_f1_score: 0.365\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.02031017708460951]\n",
      "After: [0.02031017708460951]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/15 | time: 32.75s | train_loss: 4.029 | valid_loss: 4.042 | valid_f1_score: 0.385\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.02031017708460951]\n",
      "After: [0.00803812576605873]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/15 | time: 32.69s | train_loss: 3.729 | valid_loss: 3.989 | valid_f1_score: 0.403\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.00803812576605873]\n",
      "After: [0.00803812576605873]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   5/15 | time: 32.60s | train_loss: 3.376 | valid_loss: 3.779 | valid_f1_score: 0.426\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.00803812576605873]\n",
      "After: [0.00803812576605873]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   6/15 | time: 32.75s | train_loss: 3.190 | valid_loss: 3.763 | valid_f1_score: 0.439\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.00803812576605873]\n",
      "After: [0.00803812576605873]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   7/15 | time: 32.67s | train_loss: 3.054 | valid_loss: 3.618 | valid_f1_score: 0.452\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.00803812576605873]\n",
      "After: [0.0031812359666690466]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   8/15 | time: 32.34s | train_loss: 2.939 | valid_loss: 3.659 | valid_f1_score: 0.447\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "Before: [0.0031812359666690466]\n",
      "After: [0.0031812359666690466]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   9/15 | time: 32.13s | train_loss: 2.794 | valid_loss: 3.508 | valid_f1_score: 0.468\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0031812359666690466]\n",
      "After: [0.0031812359666690466]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  10/15 | time: 32.21s | train_loss: 2.705 | valid_loss: 3.498 | valid_f1_score: 0.482\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0031812359666690466]\n",
      "After: [0.0031812359666690466]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  11/15 | time: 32.27s | train_loss: 2.659 | valid_loss: 3.463 | valid_f1_score: 0.490\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.0031812359666690466]\n",
      "After: [0.001259032586720888]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  12/15 | time: 32.23s | train_loss: 2.609 | valid_loss: 3.438 | valid_f1_score: 0.488\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-- Patience.\n",
      "\n",
      "Before: [0.001259032586720888]\n",
      "After: [0.001259032586720888]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  13/15 | time: 32.32s | train_loss: 2.538 | valid_loss: 3.425 | valid_f1_score: 0.503\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.001259032586720888]\n",
      "After: [0.001259032586720888]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch  14/15 | time: 32.29s | train_loss: 2.514 | valid_loss: 3.467 | valid_f1_score: 0.494\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Early stop.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f9681c24e94a16a43a127915e4e3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▆▅▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>valid/batch_f1</td><td>▁▃▄▄▅▆▆▆▇▇████</td></tr><tr><td>valid/batch_loss</td><td>█▅▄▄▃▃▂▂▂▁▁▁▁▁</td></tr><tr><td>valid/epoch_loss</td><td>█▅▄▄▃▃▂▂▁▁▁▁▁▁</td></tr><tr><td>valid/f1_score</td><td>▁▃▄▄▅▆▆▆▇▇█▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>2.54662</td></tr><tr><td>train/epoch_loss</td><td>2.51388</td></tr><tr><td>valid/batch_f1</td><td>0.55165</td></tr><tr><td>valid/batch_loss</td><td>3.76796</td></tr><tr><td>valid/epoch_loss</td><td>3.46737</td></tr><tr><td>valid/f1_score</td><td>0.49388</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">helpful-sweep-4</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/runs/op1l9ozv\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_heads/runs/op1l9ozv</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220418_102000-op1l9ozv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0c3awfis with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdep_embed_dim: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 1.4947224804989194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.030992680535721875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.5861788463667293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220418_102748-0c3awfis</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/runs/0c3awfis\" target=\"_blank\">hardy-sweep-5</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [0.030992680535721875]\n",
      "After: [0.030992680535721875]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/15 | time: 28.85s | train_loss: 65.885 | valid_loss: 9.236 | valid_f1_score: 0.029\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Non ci siamo...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee7f6774b094df6aa329541ab24ae90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>█▁</td></tr><tr><td>train/epoch_loss</td><td>▁</td></tr><tr><td>valid/epoch_loss</td><td>▁</td></tr><tr><td>valid/f1_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/batch_loss</td><td>73.82886</td></tr><tr><td>train/epoch_loss</td><td>65.88549</td></tr><tr><td>valid/epoch_loss</td><td>9.23599</td></tr><tr><td>valid/f1_score</td><td>0.0295</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hardy-sweep-5</strong>: <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/runs/0c3awfis\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_heads/runs/0c3awfis</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220418_102748-0c3awfis/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gdt9amfw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdep_embed_dim: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_fast: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_glove: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgrad_clipping: 0.9751372204077626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.012336724404986217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_gamma: 0.3054407573284337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsceduler_step: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220418_102828-gdt9amfw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/runs/gdt9amfw\" target=\"_blank\">clear-sweep-6</a></strong> to <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt\" target=\"_blank\">https://wandb.ai/florin-ml/NLP_HW01_heads/sweeps/xxxaknqt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [0.012336724404986217]\n",
      "After: [0.012336724404986217]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1/15 | time: 41.59s | train_loss: 20.296 | valid_loss: 5.657 | valid_f1_score: 0.200\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.012336724404986217]\n",
      "After: [0.012336724404986217]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2/15 | time: 40.48s | train_loss: 4.883 | valid_loss: 4.645 | valid_f1_score: 0.273\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.012336724404986217]\n",
      "After: [0.012336724404986217]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3/15 | time: 40.64s | train_loss: 4.128 | valid_loss: 4.327 | valid_f1_score: 0.349\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Before: [0.012336724404986217]\n",
      "After: [0.0037681384452111603]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   4/15 | time: 40.58s | train_loss: 3.794 | valid_loss: 4.128 | valid_f1_score: 0.362\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, start, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jxmxN3zL_r-X",
   "metadata": {
    "id": "jxmxN3zL_r-X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4gDm3Ll1tFlJ"
   ],
   "name": "Finally_wandb.ipynb",
   "provenance": [
    {
     "file_id": "11EBMiFn7nJUUlvacAcVRD9UiQiHINzI0",
     "timestamp": 1648722356237
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00fe27225b0a449aae027737945df70d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01e23759828c4e2bbed10ab5561f06b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "06de670d653c4271abddba393d1e3a26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0712546ebd1e4a22865d943467c61ca2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "085358ef5fe94f46958f56322362aa77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5dd2e71f7054899a42ede86fc8162ab",
      "placeholder": "​",
      "style": "IPY_MODEL_6663c7c9f19b45cba7abdbc8773754da",
      "value": "0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "09d32109df444907a30761ee05ebdbd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59dd067dc77b4febbf3a93f250003c4c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_13bee564ce304190801bea63aeed3ef3",
      "value": 1
     }
    },
    "09e323dafcbb453995937940ccfc682c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d3b7bc31de14c2f941c0311f6c1b57f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b588a4698f646c0a844c3250cd46a20",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e81969779634e53bf837046e85c1e2b",
      "value": 1
     }
    },
    "0e81969779634e53bf837046e85c1e2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "13bee564ce304190801bea63aeed3ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "13e27c7469364ed3b14ad1b33aa75755": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_607a98df57ff44e4ab9abeeeb86d13bc",
      "placeholder": "​",
      "style": "IPY_MODEL_da1e332bdaef4af998bae23efae79e0d",
      "value": "0.012 MB of 0.012 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "1490b01999a1429eb118d4a4379524b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14911de88f8e49b7907f13409fc427d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d3bd75b7c0f4db385e631b2b808679d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8dbb309fb1746beab9a8fd003fed624",
      "value": 1
     }
    },
    "1b588a4698f646c0a844c3250cd46a20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c51867d12494c07a5e3b0ea98cab176": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_892ae65ecf4940ac881daf2910cbb6b7",
       "IPY_MODEL_0d3b7bc31de14c2f941c0311f6c1b57f"
      ],
      "layout": "IPY_MODEL_839c58584d874b7fa20f2d1de206c931"
     }
    },
    "1ee7f6774b094df6aa329541ab24ae90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae55a1e880604ec3a72d24c3a409e46a",
       "IPY_MODEL_46e2560b24a14203b198762df500a6c6"
      ],
      "layout": "IPY_MODEL_4e736154092a4a9d9b82438e920d28fe"
     }
    },
    "207f8a637d5943ffafb7e900a3041cde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fd5b2be54654b2ba644d0049f5f93b5",
      "placeholder": "​",
      "style": "IPY_MODEL_ed4c46828a9c4aeebe60991aa0b8adc3",
      "value": "0.012 MB of 0.012 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "214b8b5f1aeb43fd8983757ee13f1c91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25a051869db74c3eaf7751dbd3e6a4b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2978c09f0df6434e8bfd0b327ed1ad68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9017b63092e478981e43703016c7732",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e89029996ff14433aebc7636e3d50d57",
      "value": 1
     }
    },
    "2c6c53c5cc974f34b917f04c5854bb09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d7e1904f62544f2bd6b049ea4df6898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfa78dbf050b4edb8da3844808d2f11f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eee0071b7d10470c98d94f1244e8d4d3",
      "value": 1
     }
    },
    "2e1a5d81d9534f48b4a2bf4d209aa5b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f081c5121e14c45af8312216110d06d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30e9f82c423049ffbb4b4b84c73248d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77773eb6e53e45ee993bc9ab3b84b478",
       "IPY_MODEL_99d795c55d3b4b0d9e89ef9bc4a9723e"
      ],
      "layout": "IPY_MODEL_00fe27225b0a449aae027737945df70d"
     }
    },
    "3476b800a6e2466b9a992546ac59249b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bf90e06e0984e7b9b785af1717e90ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_909e333c1e4c458ab05f044e76c479b8",
       "IPY_MODEL_5f360bcd113e4c4aaefbf7ebfe501938"
      ],
      "layout": "IPY_MODEL_ec61ade6d59346f0842c1fa3f055dbcd"
     }
    },
    "3d8d3473a88648f39027681deed3e44e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e88a2766f054549b995e42d339bb6ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41691a38d63b42f5bbc00c1da9243be1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9fb06aa4d5e410a9cec4a592a185a7f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_765764bd0c3f43e6b8b7f252740c2a47",
      "value": 1
     }
    },
    "46e2560b24a14203b198762df500a6c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b820ab64a8843ed9c3c4cf1d56773d0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_75cf22f1183b475a8bcb8ede4dd6e123",
      "value": 1
     }
    },
    "476b0d4c1589457c9ee6ec5ee558a359": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_91a2c027c01348a894e41cd2cd1b160a",
       "IPY_MODEL_2d7e1904f62544f2bd6b049ea4df6898"
      ],
      "layout": "IPY_MODEL_bfae5df962da49888da011f94d0b48ac"
     }
    },
    "47d3f588d0d44eb8b537e471857be23f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "49c086a2d5834afa84f775ced2097406": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e736154092a4a9d9b82438e920d28fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54bbc180718643859d30d49b38f36f26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8db0a4f9faf44b47a44aac218958faad",
      "placeholder": "​",
      "style": "IPY_MODEL_b65db98563784625a0f61372b3568b1f",
      "value": "0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "55247454d83d4a29befd378f8ccef310": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_085358ef5fe94f46958f56322362aa77",
       "IPY_MODEL_91c8a00d9b014d738ba7082a82e46923"
      ],
      "layout": "IPY_MODEL_f504020f277847a69aa89550e75383d1"
     }
    },
    "56109661560c488ea58ee9ad5d5c4684": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58cfdf686744494a9208d0f49c46179e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85c2a66a0c174bc1afb0566d0c5a2839",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3476b800a6e2466b9a992546ac59249b",
      "value": 1
     }
    },
    "59dd067dc77b4febbf3a93f250003c4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d9d2abf40af4f3881fb6f93540cdcd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e59840764f04c11924d0600df775241": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f360bcd113e4c4aaefbf7ebfe501938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09e323dafcbb453995937940ccfc682c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47d3f588d0d44eb8b537e471857be23f",
      "value": 1
     }
    },
    "5fb8b642acf14f0b971816c07dbb121f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "607a98df57ff44e4ab9abeeeb86d13bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "637e90c0090c42db9759b3897e6dc147": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc571ca9ee8d45fb92b57c1506159bb6",
       "IPY_MODEL_8a28c8cd41fd4622a481aa7aef1361de"
      ],
      "layout": "IPY_MODEL_eaa9f19f204149c6b0eec47cd5c6ea1f"
     }
    },
    "6663c7c9f19b45cba7abdbc8773754da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6bf2e7643b05436fb1fee8f7ed900e46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c0c24aa3ef9438fab35161dc5318e5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0b0ae43cc5a4ed2b1c66f545f637b95",
      "placeholder": "​",
      "style": "IPY_MODEL_f790512d21804e279a71f18b1bc234c7",
      "value": "0.013 MB of 0.013 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "6c5e321c94af4b47a8155d4177570599": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea79a68050804ff785986b7abb1c5578",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7545e720d212447a83ff1cfbc11332e0",
      "value": 1
     }
    },
    "6fd5b2be54654b2ba644d0049f5f93b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70f9681c24e94a16a43a127915e4e3f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c0c24aa3ef9438fab35161dc5318e5a",
       "IPY_MODEL_6c5e321c94af4b47a8155d4177570599"
      ],
      "layout": "IPY_MODEL_2f081c5121e14c45af8312216110d06d"
     }
    },
    "7545e720d212447a83ff1cfbc11332e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "75500b44ec5f46b787b278981b91eadc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75cf22f1183b475a8bcb8ede4dd6e123": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "765764bd0c3f43e6b8b7f252740c2a47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "77773eb6e53e45ee993bc9ab3b84b478": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56109661560c488ea58ee9ad5d5c4684",
      "placeholder": "​",
      "style": "IPY_MODEL_75500b44ec5f46b787b278981b91eadc",
      "value": "0.013 MB of 0.013 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "79531487a4bd4b98865e3cf159ea6107": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7b820ab64a8843ed9c3c4cf1d56773d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "827ba330871b480899f2b9e56d5bed26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aaded8f7a5c540ce9a8d5c2bd208870c",
      "placeholder": "​",
      "style": "IPY_MODEL_3e88a2766f054549b995e42d339bb6ec",
      "value": "0.012 MB of 0.012 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "839c58584d874b7fa20f2d1de206c931": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83deb34788974b4abf97f4d54f9d311d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85c2a66a0c174bc1afb0566d0c5a2839": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "892ae65ecf4940ac881daf2910cbb6b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1afc5b7695245738aaf09187fdde5ab",
      "placeholder": "​",
      "style": "IPY_MODEL_1490b01999a1429eb118d4a4379524b1",
      "value": "0.012 MB of 0.012 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "8a28c8cd41fd4622a481aa7aef1361de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83deb34788974b4abf97f4d54f9d311d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc6458adeb6a4a30bebba3308ae0fe06",
      "value": 1
     }
    },
    "8c36f9584e474365ad60aaebb4714339": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8db0a4f9faf44b47a44aac218958faad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "905fc698eb874106ae2d21f594c22157": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "909e333c1e4c458ab05f044e76c479b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7deb98f417b49cb9f9bb3e090c25d2b",
      "placeholder": "​",
      "style": "IPY_MODEL_b8f9255a9a2a4c498b2d59dc0725fed4",
      "value": "0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "91a2c027c01348a894e41cd2cd1b160a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06de670d653c4271abddba393d1e3a26",
      "placeholder": "​",
      "style": "IPY_MODEL_905fc698eb874106ae2d21f594c22157",
      "value": "0.013 MB of 0.013 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "91c8a00d9b014d738ba7082a82e46923": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b372f722d1c04eb79518b390cb5f510d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d72888ddbbf149dd93235230f4ec6eaa",
      "value": 1
     }
    },
    "9305ee92e3ea4bb9b2db61300189fe66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54bbc180718643859d30d49b38f36f26",
       "IPY_MODEL_09d32109df444907a30761ee05ebdbd5"
      ],
      "layout": "IPY_MODEL_214b8b5f1aeb43fd8983757ee13f1c91"
     }
    },
    "99d795c55d3b4b0d9e89ef9bc4a9723e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1ebdcf4285642c392a0fad22659ada7",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5fb8b642acf14f0b971816c07dbb121f",
      "value": 1
     }
    },
    "9c18ca217b224f43ad6ba0f63114decb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_13e27c7469364ed3b14ad1b33aa75755",
       "IPY_MODEL_d592240840f7454ea25b29dd995f1eb9"
      ],
      "layout": "IPY_MODEL_6bf2e7643b05436fb1fee8f7ed900e46"
     }
    },
    "9d3bd75b7c0f4db385e631b2b808679d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e2b12fa35bf4486980540768670d8a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0a40656168d4aed82b0981be7300590": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f8bef87c674345299e0fef8feccc4739",
       "IPY_MODEL_41691a38d63b42f5bbc00c1da9243be1"
      ],
      "layout": "IPY_MODEL_0712546ebd1e4a22865d943467c61ca2"
     }
    },
    "a0b0ae43cc5a4ed2b1c66f545f637b95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7deb98f417b49cb9f9bb3e090c25d2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8382fa2e9d245a18111612c0ded8c50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cfc354da138b47c1b3b07b885b115534",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_01e23759828c4e2bbed10ab5561f06b7",
      "value": 1
     }
    },
    "a85176ff3f524c1bb2a3a6bb68160f5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3a0a14eb72b4739905a8ebbd4efd1c2",
       "IPY_MODEL_58cfdf686744494a9208d0f49c46179e"
      ],
      "layout": "IPY_MODEL_8c36f9584e474365ad60aaebb4714339"
     }
    },
    "a9282b4969f54a15bd60be116d706759": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aaded8f7a5c540ce9a8d5c2bd208870c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae4c077dec1a4df4bd295e0eff3f28d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae55a1e880604ec3a72d24c3a409e46a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d082108d23f04ee6bb30ff0ae5cf0f0f",
      "placeholder": "​",
      "style": "IPY_MODEL_a9282b4969f54a15bd60be116d706759",
      "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "b1fe8ccc787a480294c02630ed544a45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_827ba330871b480899f2b9e56d5bed26",
       "IPY_MODEL_2978c09f0df6434e8bfd0b327ed1ad68"
      ],
      "layout": "IPY_MODEL_2c6c53c5cc974f34b917f04c5854bb09"
     }
    },
    "b372f722d1c04eb79518b390cb5f510d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b65db98563784625a0f61372b3568b1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8f9255a9a2a4c498b2d59dc0725fed4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc571ca9ee8d45fb92b57c1506159bb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49c086a2d5834afa84f775ced2097406",
      "placeholder": "​",
      "style": "IPY_MODEL_5e59840764f04c11924d0600df775241",
      "value": "0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "bfae5df962da49888da011f94d0b48ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1afc5b7695245738aaf09187fdde5ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5dd2e71f7054899a42ede86fc8162ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c62144738d5f418f9e428d1b5c662775": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e2b12fa35bf4486980540768670d8a5",
      "placeholder": "​",
      "style": "IPY_MODEL_25a051869db74c3eaf7751dbd3e6a4b7",
      "value": "0.013 MB of 0.013 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "ce6332a62a7946728f876cdebb64f68f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_207f8a637d5943ffafb7e900a3041cde",
       "IPY_MODEL_a8382fa2e9d245a18111612c0ded8c50"
      ],
      "layout": "IPY_MODEL_e85a62e2f8a847ae982f43321ad90f13"
     }
    },
    "cfc354da138b47c1b3b07b885b115534": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d082108d23f04ee6bb30ff0ae5cf0f0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1ebdcf4285642c392a0fad22659ada7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3a0a14eb72b4739905a8ebbd4efd1c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d9d2abf40af4f3881fb6f93540cdcd4",
      "placeholder": "​",
      "style": "IPY_MODEL_3d8d3473a88648f39027681deed3e44e",
      "value": "0.013 MB of 0.013 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "d592240840f7454ea25b29dd995f1eb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f758e4a169034f15a340d0f8c9dd59df",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79531487a4bd4b98865e3cf159ea6107",
      "value": 1
     }
    },
    "d72888ddbbf149dd93235230f4ec6eaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d9017b63092e478981e43703016c7732": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da1e332bdaef4af998bae23efae79e0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc6458adeb6a4a30bebba3308ae0fe06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dfa78dbf050b4edb8da3844808d2f11f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e85a62e2f8a847ae982f43321ad90f13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e89029996ff14433aebc7636e3d50d57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8dbb309fb1746beab9a8fd003fed624": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e9fb06aa4d5e410a9cec4a592a185a7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea79a68050804ff785986b7abb1c5578": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaa9f19f204149c6b0eec47cd5c6ea1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec61ade6d59346f0842c1fa3f055dbcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed4c46828a9c4aeebe60991aa0b8adc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eee0071b7d10470c98d94f1244e8d4d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "efd356d12409446f8c63bc34bb66d19f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c62144738d5f418f9e428d1b5c662775",
       "IPY_MODEL_14911de88f8e49b7907f13409fc427d5"
      ],
      "layout": "IPY_MODEL_fde3655a2076428186cef6603d45ce66"
     }
    },
    "f504020f277847a69aa89550e75383d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f758e4a169034f15a340d0f8c9dd59df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f790512d21804e279a71f18b1bc234c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8bef87c674345299e0fef8feccc4739": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae4c077dec1a4df4bd295e0eff3f28d1",
      "placeholder": "​",
      "style": "IPY_MODEL_2e1a5d81d9534f48b4a2bf4d209aa5b3",
      "value": "0.012 MB of 0.012 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "fde3655a2076428186cef6603d45ce66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
